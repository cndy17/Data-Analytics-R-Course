[
  {
    "objectID": "data-projects.html",
    "href": "data-projects.html",
    "title": "Data Projects",
    "section": "",
    "text": "Elect\n\nAnalysis of the effect of the US Electoral College on US Presidential elections, comparing different ways that states allocate their Electoral College Votes to determine whether this has any effect on who is elected the President of these United States. Visualizes spatial data, working with official electoral records, and accessing public data repositories, such as those of the US Census Bureau.\nView Report\n\n\nProposing a Successful Film\n\nAn investigation of imdb data to act as Hollywood development executives, diving deep into Hollywood history to develop a pitch for a new movie. Working with large data and relational data structures\nView Report\n\n\nFiscal Characteristics of Major US Public Transit Systems\n\nAn investigation of ridership and the fiscal characteristics of US public transit authorities. In this project, I utilize dplyr operations (mutate, group_by, summarize, select, arrange, rename) in R to produce summary statistics.\nView Report"
  },
  {
    "objectID": "mp02.html",
    "href": "mp02.html",
    "title": "Proposing a Successful Film",
    "section": "",
    "text": "This project uses data made available by Internet Movie Database (IMDb). While I did intially use the full data set in my analysis, I switched over to using a sub-sampled pre-processed data because my computer was struggling to handle the full data.\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(gt)\n\nget_imdb_file &lt;- function(fname){\n  fname_ext &lt;- paste0(fname, \".csv.zip\")\n  as.data.frame(readr::read_csv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS &lt;- get_imdb_file(\"name_basics_small\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title_basics_small\")\nTITLE_EPISODES &lt;- get_imdb_file(\"title_episodes_small\")\nTITLE_RATINGS &lt;- get_imdb_file(\"title_ratings_small\")\nTITLE_CREW &lt;- get_imdb_file(\"title_crew_small\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title_principals_small\")\n\nBelow, I am converting the birth year and death year to numeric data types.\n\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n  mutate(birthYear = as.numeric(birthYear), # numeric birth years\n         deathYear = as.numeric(deathYear))\n\nWith that, the data I am using has been narrowed down significantly to a smaller and manageable sub sample.\n\n\n\n\nDisplay Code\nlibrary(DT)\nlibrary(dplyr)\n\nsample_n(NAME_BASICS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_BASICS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_CREW, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_EPISODES, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_RATINGS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_PRINCIPALS, 1000) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp02.html#data",
    "href": "mp02.html#data",
    "title": "Proposing a Successful Film",
    "section": "",
    "text": "This project uses data made available by Internet Movie Database (IMDb). While I did intially use the full data set in my analysis, I switched over to using a sub-sampled pre-processed data because my computer was struggling to handle the full data.\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(gt)\n\nget_imdb_file &lt;- function(fname){\n  fname_ext &lt;- paste0(fname, \".csv.zip\")\n  as.data.frame(readr::read_csv(fname_ext, lazy=FALSE))\n}\n\nNAME_BASICS &lt;- get_imdb_file(\"name_basics_small\")\nTITLE_BASICS     &lt;- get_imdb_file(\"title_basics_small\")\nTITLE_EPISODES &lt;- get_imdb_file(\"title_episodes_small\")\nTITLE_RATINGS &lt;- get_imdb_file(\"title_ratings_small\")\nTITLE_CREW &lt;- get_imdb_file(\"title_crew_small\")\nTITLE_PRINCIPALS &lt;- get_imdb_file(\"title_principals_small\")\n\nBelow, I am converting the birth year and death year to numeric data types.\n\nNAME_BASICS &lt;- NAME_BASICS |&gt;\n  mutate(birthYear = as.numeric(birthYear), # numeric birth years\n         deathYear = as.numeric(deathYear))\n\nWith that, the data I am using has been narrowed down significantly to a smaller and manageable sub sample.\n\n\n\n\nDisplay Code\nlibrary(DT)\nlibrary(dplyr)\n\nsample_n(NAME_BASICS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_BASICS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_CREW, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_EPISODES, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_RATINGS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n\n\n\nDisplay Code\nsample_n(TITLE_PRINCIPALS, 1000) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp02.html#preliminary-exploration",
    "href": "mp02.html#preliminary-exploration",
    "title": "Proposing a Successful Film",
    "section": "Preliminary Exploration",
    "text": "Preliminary Exploration\n1. How many movies are in our data set? How many TV series? How many TV episodes?\n\n\nDisplay Code\nlibrary(gt)\nTITLE_BASICS |&gt;\n  group_by(titleType) |&gt;\n  filter(titleType %in% c(\"movie\", \"tvSeries\", \"tvEpisode\" )) |&gt;\n  summarise(count = n()) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Number of Title Types\"\n  ) |&gt;\n  cols_label( # display column names\n    titleType = \"Type\",\n    count = \"Count\"\n  )\n\n\n\n\n\n\n\n\nNumber of Title Types\n\n\nType\nCount\n\n\n\n\nmovie\n131662\n\n\ntvEpisode\n155722\n\n\ntvSeries\n29789\n\n\n\n\n\n\n\n2. Who is the oldest living person in our data set?\n\n\nDisplay Code\nNAME_BASICS |&gt; \n  filter(is.na(deathYear)) |&gt; # filter for those without a deathYear\n  arrange(birthYear) |&gt; \n  slice(1) |&gt;\n  gt() |&gt; # create a display table\n  cols_label( # display column names\n    primaryName = \"Name\",\n    birthYear = \"Birth Year\"\n  )\n\n\n\n\n\n\n\n\nnconst\nName\nBirth Year\ndeathYear\nprimaryProfession\nknownForTitles\n\n\n\n\nnm5671597\nRobert De Visée\n1655\nNA\ncomposer,soundtrack\ntt2219674,tt1743724,tt0441074,tt14426058\n\n\n\n\n\n\n\nThe results of this first query says Robert De Visee but Robert was born in 1655, which does not make sense at all. A quick Google search says that the oldest person alive in 2024 is 116. Given that, let us filter for people born after 1914.\n\n\nDisplay Code\nNAME_BASICS |&gt; \n  filter(is.na(deathYear)) |&gt; # filter for those without a deathYear\n  filter(birthYear&gt;=1914) |&gt;\n  arrange(birthYear) |&gt; \n  slice(1)\n\n\n     nconst    primaryName birthYear deathYear primaryProfession\n1 nm0029349 Antonio Anelli      1914        NA             actor\n                           knownForTitles\n1 tt0072364,tt0068416,tt0065460,tt0068973\n\n\nLet’s perform a sanity check by confirming online. The internet says Antonio Anelli died on 12 May 1977.\n\n\nDisplay Code\nNAME_BASICS |&gt; \n  filter(is.na(deathYear)) |&gt; # filter for those without a deathYear\n  filter(birthYear&gt;=1916) |&gt;\n  arrange(birthYear) |&gt; \n  slice(1)\n\n\n     nconst primaryName birthYear deathYear                   primaryProfession\n1 nm0048527   Ivy Baker      1916        NA costume_department,costume_designer\n                           knownForTitles\n1 tt0041959,tt0054518,tt0066344,tt0042522\n\n\nIvy Baker born in 1916 and her bio on IMDb does not have a death year.\nTo be safe, let’s check for a year before 1916 and look at 1915.\n\n\nDisplay Code\nNAME_BASICS |&gt; \n  filter(is.na(deathYear)) |&gt; # filter for those without a deathYear\n  filter(birthYear&gt;=1915) |&gt;\n  arrange(birthYear) |&gt; \n  slice(1)\n\n\n     nconst    primaryName birthYear deathYear     primaryProfession\n1 nm0015296 Akhtar-Ul-Iman      1915        NA writer,actor,director\n                           knownForTitles\n1 tt0059893,tt0175450,tt0060689,tt0158587\n\n\nThe result says Akhtar-Ul-Iman but according to Wikipedia, he died on March 9, 1996.\n3. There is one TV Episode in this data set with a perfect 10/10 rating and 200,000 IMDb ratings.\n\n\nDisplay Code\nTITLE_RATINGS |&gt; \n  left_join(TITLE_EPISODES, by = \"tconst\") |&gt; # join using tconst\n  filter(averageRating == 10.0 & numVotes &gt;= 200000) |&gt; # filter by averageRating and numVotes\n  left_join(TITLE_BASICS, by = \"tconst\") |&gt; # join using tconst\n  left_join(TITLE_BASICS, join_by(\"parentTconst\" == \"tconst\")) |&gt;\n  select(primaryTitle.y, primaryTitle.x, averageRating, numVotes) |&gt; # select just the title, average rating, and number of votes\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Perfect TV Episode\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryTitle.y = \"TV Show\",\n    primaryTitle.x = \"Episode\",\n    averageRating = \"Average Rating\",\n    numVotes = \"Number of Votes\"\n  )\n\n\n\n\n\n\n\n\nPerfect TV Episode\n\n\nTV Show\nEpisode\nAverage Rating\nNumber of Votes\n\n\n\n\nBreaking Bad\nOzymandias\n10\n227589\n\n\n\n\n\n\n\n4. What four projects is the actor Mark Hammill most known for?\n\n\nDisplay Code\nlibrary(tidyr)\nNAME_BASICS |&gt; \n  filter(primaryName == \"Mark Hamill\") |&gt; \n  select(knownForTitles) |&gt; \n  separate_rows(knownForTitles, sep = \",\") |&gt;  # Split by comma to make each knownForTitle a row\n  left_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt; # join to TITLE_BASICS on tconst\n  select(primaryTitle) |&gt; \n  head(4) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Titles Mark Hammil is Known For\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryTitle = \"Title\"\n  )\n\n\n\n\n\n\n\n\nTitles Mark Hammil is Known For\n\n\nTitle\n\n\n\n\nStar Wars: Episode IV - A New Hope\n\n\nStar Wars: Episode VIII - The Last Jedi\n\n\nStar Wars: Episode V - The Empire Strikes Back\n\n\nStar Wars: Episode VI - Return of the Jedi\n\n\n\n\n\n\n\n5. What TV series, with more than 12 episodes, has the highest average rating?\n\n\nDisplay Code\n# Find the highest-rated TV series with more than 12 episodes\n# tt15613780        9.7           318 Craft Games\n\nTITLE_BASICS |&gt;\n  filter(titleType == \"tvSeries\") |&gt;\n  right_join(TITLE_EPISODES, by = c(\"tconst\" = \"parentTconst\")) |&gt;\n  group_by(tconst) |&gt;\n  mutate(episode_count = n()) |&gt;\n  ungroup() |&gt;\n  filter(episode_count &gt; 12) |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  arrange(desc(averageRating)) |&gt;\n  select(primaryTitle, averageRating, episode_count) |&gt;\n  head(1) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Highest-Rated TV Series with More Than 12 Episodes\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryTitle = \"TV Series\",\n    averageRating = \"Average Rating\",\n    episode_count = \"Number of Episodes\"\n  )\n\n\n\n\n\n\n\n\nHighest-Rated TV Series with More Than 12 Episodes\n\n\nTV Series\nAverage Rating\nNumber of Episodes\n\n\n\n\nCraft Games\n9.7\n318\n\n\n\n\n\n\n\n6. Is it true that episodes from later seasons of Happy Days have lower average ratings than the early seasons? The TV series Happy Days (1974-1984) gives us the common idiom “jump the shark”. The phrase comes from a controversial fifth season episode (aired in 1977) in which a lead character literally jumped over a shark on water skis. Idiomatically, it is used to refer to the moment when a once-great show becomes ridiculous and rapidly looses quality.\nFirst, I’m finding the tconst for Happy Days.\n\n\nDisplay Code\nTITLE_BASICS |&gt;\n  filter(originalTitle == \"Happy Days\") |&gt;\n  filter(titleType == \"tvSeries\") |&gt;\n  filter(startYear == \"1974\") |&gt;\n  select(tconst) # find the tconst for Happy Days\n\n\n     tconst\n1 tt0070992\n\n\nWe can see below that seasons 1 through 4 do well in terms of average rating. Aside from season 11, the seasons after season 5 are all in the bottom half of ratings. Meanwhile, season 3 has the highest rating of 7.7.\n\n\nDisplay Code\nTITLE_EPISODES |&gt; \n  filter(parentTconst == \"tt0070992\") |&gt; \n  left_join(TITLE_RATINGS, join_by(\"tconst\" )) |&gt; \n  group_by(seasonNumber) |&gt; \n  summarize(avg_rating = mean(averageRating, na.rm = TRUE)) |&gt; \n  mutate(seasonNumber = as.numeric(seasonNumber)) |&gt;\n  select(seasonNumber, avg_rating) |&gt;\n  arrange(desc(avg_rating)) |&gt; # arrange by average rating in descending order\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Ratings for Happy Days by Season\"\n  ) |&gt;\n  cols_label( # display column names\n    seasonNumber = \"Season\",\n    avg_rating = \"Average Rating\"\n  )\n\n\n\n\n\n\n\n\nRatings for Happy Days by Season\n\n\nSeason\nAverage Rating\n\n\n\n\n3\n7.700000\n\n\n2\n7.691304\n\n\n1\n7.581250\n\n\n4\n7.428000\n\n\n11\n7.333333\n\n\n6\n7.018750\n\n\n5\n7.000000\n\n\n10\n6.700000\n\n\n9\n6.400000\n\n\n7\n6.333333\n\n\n8\n5.400000\n\n\n\n\n\n\n\nIn the plot below, we see that there is a indeed a dip in ratings in the later seasons of the show.\n\n\nDisplay Code\nseason_ratings &lt;- TITLE_EPISODES |&gt; \n  filter(parentTconst == \"tt0070992\") |&gt; \n  left_join(TITLE_RATINGS, join_by(\"tconst\" )) |&gt; \n  group_by(seasonNumber) |&gt; \n  summarize(avg_rating = mean(averageRating, na.rm = TRUE)) |&gt; \n  mutate(seasonNumber = as.numeric(seasonNumber)) |&gt;\n  select(seasonNumber, avg_rating) |&gt;\n  arrange(desc(seasonNumber)) # arrange by season in descending order\n\nlibrary(ggplot2)\n# Bar chart of average ratings by season \nggplot(season_ratings, aes(x = seasonNumber, y = avg_rating)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Average Ratings of Happy Days by Season\",\n       x = \"Season Number\",\n       y = \"Average Rating\") +\n  ylim(0,10) +\n  scale_x_continuous(breaks = seq(1, 11, by = 1)) +\n  geom_text(aes(label=round(avg_rating, digits = 1)), vjust=0)"
  },
  {
    "objectID": "mp02.html#threshold-for-a-solid-title",
    "href": "mp02.html#threshold-for-a-solid-title",
    "title": "Proposing a Successful Film",
    "section": "Threshold for a Solid Title",
    "text": "Threshold for a Solid Title\nTo come up with a numerical threshold for a project to be a ‘success’ and determine a value such that movies above are all “solid” or better, I am going to use summary statistics. The 3rd Q is 0.6 and so I thinkk a score greater than 0.6 is “solid” and above the average movie.\n\n\nDisplay Code\nggplot(TITLE_RATINGS, aes(x=success_score)) + geom_histogram()\n\n\n\n\n\n\n\n\n\nDisplay Code\nsummary(TITLE_RATINGS$success_score)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2046  0.4987  0.5517  0.5484  0.6000  0.9653"
  },
  {
    "objectID": "mp02.html#examining-success-by-genre-and-decade",
    "href": "mp02.html#examining-success-by-genre-and-decade",
    "title": "Proposing a Successful Film",
    "section": "Examining Success by Genre and Decade",
    "text": "Examining Success by Genre and Decade\nIn this section, we explore the interplay between film genres and their success across different decades, aiming to uncover trends that can inform a future project. By analyzing the performance of various genres over time, we can identify promising opportunities for an upcoming film.\n\n\nDisplay Code\n# highest average score\n# Biography, Adventure, Animation\nTITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt;  # Corrected join syntax\n  separate_longer_delim(genres, \",\") |&gt; \n  group_by(genres) |&gt;  # Group by genres\n  summarise(avg_score = mean(success_score, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  arrange(desc(avg_score)) |&gt;\n  head(5)  |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Genres with Top 10 Average Success Scores\"\n  ) |&gt;\n  cols_label( # display column names\n    genres = \"Genre\",\n    avg_score = \"Average Success Score\"\n  )\n\n\n\n\n\n\n\n\nGenres with Top 10 Average Success Scores\n\n\nGenre\nAverage Success Score\n\n\n\n\nBiography\n0.5739485\n\n\nAdventure\n0.5732288\n\n\nAnimation\n0.5721809\n\n\nCrime\n0.5692845\n\n\nHistory\n0.5671059\n\n\n\n\n\n\n\nThe average success scores for the various genres seem fairly close to each other. Instead, we can count the number of success scores greater than the threshold of 0.6 for each genre.\n\n\nDisplay Code\n# Drama, Comedy, Action\nTITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt;  # Corrected join syntax\n  filter(success_score &gt;= 0.6) |&gt; # greater than threshold\n  separate_longer_delim(genres, \",\") |&gt; \n  group_by(genres) |&gt;  # Group by genres\n  summarise(success_count = n()) |&gt;\n  ungroup() |&gt;\n  arrange(desc(success_count)) |&gt;\n  head(5) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Genres with Top 10 Average Success Scores\"\n  ) |&gt;\n  cols_label( # display column names\n    genres = \"Genre\",\n    success_count = \"Number of Success Scores &gt; 0.60\"\n  )\n\n\n\n\n\n\n\n\nGenres with Top 10 Average Success Scores\n\n\nGenre\nNumber of Success Scores &gt; 0.60\n\n\n\n\nDrama\n52577\n\n\nComedy\n30306\n\n\nAction\n24394\n\n\nAdventure\n19408\n\n\nCrime\n19341\n\n\n\n\n\n\n\nWhat was the genre with the most “successes” in each decade? What genre consistently has the most “successes”?\n\n\nDisplay Code\n# Success by genre and decade\nsuccess_by_decade &lt;- TITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n  filter(success_score &gt;= 0.6) |&gt; \n  mutate(decade = floor(as.integer(startYear) / 10) * 10) |&gt;  # Create a decade column\n  separate_longer_delim(genres, \",\") |&gt; \n  group_by(decade, genres) |&gt; \n  summarise(success_count = n()) |&gt; \n  ungroup() |&gt;\n  arrange(decade, desc(success_count)) \n\n# Find the genre with the most successes in each decade\ntop_genre_per_decade &lt;- success_by_decade |&gt;\n  group_by(decade) |&gt; \n  slice_max(success_count, n = 1) # select top performing\n\n# Count how many times each genre is the highest in each decade\ntop_genre_per_decade |&gt;\n  group_by(genres) |&gt; \n  summarise(highest_count = n()) |&gt; \n  arrange(desc(highest_count)) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Number of Times Genres Had the Most Successes of a Decade\"\n  ) |&gt;\n  cols_label( # display column names\n    genres = \"Genre\",\n    highest_count = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\nNumber of Times Genres Had the Most Successes of a Decade\n\n\nGenre\nFrequency\n\n\n\n\nDrama\n12\n\n\nShort\n3\n\n\nComedy\n2\n\n\nDocumentary\n2\n\n\nSport\n1\n\n\n\n\n\n\n\nWhat genre used to reliably produced “successes” and has fallen out of favor?\n\n\nDisplay Code\nlibrary(ggrepel)\nlibrary(ggplot2)\n\ngenre_success &lt;- TITLE_BASICS |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  filter(success_score &gt; 0.6) |&gt;  # Set your success threshold\n  filter(!is.na(startYear) & !is.na(success_score)) |&gt;\n  separate_longer_delim(genres, \",\") |&gt; \n  group_by(genres, startYear) |&gt;\n  summarise(success_count = n())\n\ngenre_success |&gt;\n  ggplot(aes(x = startYear, y = success_count, color = genres)) +\n  geom_line(size = 0.5) +       # Use lines to connect points\n  geom_point(size = 1) +      # Add points for each data point\n  labs(\n    title = \"Count of Successful Movies by Genre Over Time\",\n    x = \"Year\",\n    y = \"Count of Successful Movies\",\n    color = \"Genre\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nWhat genre has produced the most “successes” since 2010? It seems that many films just get counted as Dramas with 32923 Dramas.\n\n\nDisplay Code\nTITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n  filter(success_score &gt;= 0.6, startYear &gt;= 2010) |&gt; # filter by 2010\n  separate_longer_delim(genres, \",\") |&gt; \n  group_by(genres) |&gt; \n  summarise(success_count = n()) |&gt; \n  ungroup() |&gt;\n  arrange(desc(success_count)) |&gt;\n  head(5) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Success Count by Genre\"\n  ) |&gt;\n  cols_label( # display column names\n    genres = \"Genre\",\n    success_count = \"Success Count\"\n  )\n\n\n\n\n\n\n\n\nSuccess Count by Genre\n\n\nGenre\nSuccess Count\n\n\n\n\nDrama\n32923\n\n\nComedy\n16142\n\n\nAction\n15961\n\n\nCrime\n12626\n\n\nAdventure\n11665\n\n\n\n\n\n\n\nDisplay Code\nrecent_top_genres &lt;- TITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n  filter(success_score &gt;= 0.6, startYear &gt;= 2010) |&gt; \n  separate_longer_delim(genres, \",\") |&gt; \n  group_by(genres) |&gt; \n  summarise(success_count = n()) |&gt; \n  ungroup() |&gt;\n  arrange(desc(success_count)) |&gt;\n  head(5)\n\nrecent_top_genres |&gt;\n  ggplot(aes(x = genres, y = success_count, fill = genres)) +\n  geom_bar(stat=\"identity\") +\n  labs(\n    title = \"Count of Successful Movies by Genre Over Time\",\n    x = \"Genre\",\n    y = \"Count of Successful Movies\",\n    color = \"Genre\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nWithin the Drama genre, what were the most successful movies? It turns out the top movies we saw before all fall within the Drama genre as well.\n\n\nDisplay Code\nTITLE_RATINGS |&gt; \n  arrange(desc(success_score)) |&gt;  \n  left_join(TITLE_BASICS, join_by(\"tconst\" )) |&gt; \n  filter(titleType == 'movie') |&gt; \n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Drama\") |&gt;\n  select(primaryTitle, success_score, averageRating, numVotes) |&gt;\n  head(10) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Most Successful Drama Movies\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryTitle = \"Title\",\n    success_score = \"Success Score\",\n    averageRating = \"Average Rating\",\n    numVotes = \"Number of Votes\"\n  )\n\n\n\n\n\n\n\n\nMost Successful Drama Movies\n\n\nTitle\nSuccess Score\nAverage Rating\nNumber of Votes\n\n\n\n\nThe Shawshank Redemption\n0.9648769\n9.3\n2942823\n\n\nThe Dark Knight\n0.9495972\n9.0\n2922922\n\n\nThe Godfather\n0.9477853\n9.2\n2051186\n\n\nThe Lord of the Rings: The Return of the King\n0.9371353\n9.0\n2013824\n\n\nPulp Fiction\n0.9359758\n8.9\n2260017\n\n\nFight Club\n0.9326142\n8.8\n2374722\n\n\nThe Lord of the Rings: The Fellowship of the Ring\n0.9326021\n8.9\n2043202\n\n\nForrest Gump\n0.9315685\n8.8\n2301630\n\n\nSchindler's List\n0.9267397\n9.0\n1475891\n\n\nThe Godfather Part II\n0.9246497\n9.0\n1386499\n\n\n\n\n\n\n\nWhat about the second most successful genre, Comedy?\n\n\nDisplay Code\nTITLE_RATINGS |&gt; \n  arrange(desc(success_score)) |&gt;  \n  left_join(TITLE_BASICS, join_by(\"tconst\" )) |&gt; \n  filter(titleType == 'movie') |&gt; \n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Comedy\") |&gt;\n  select(primaryTitle, success_score, averageRating, numVotes) |&gt;\n  head(5) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Most Successful Comedy Movies\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryTitle = \"Title\",\n    success_score = \"Success Score\",\n    averageRating = \"Average Rating\",\n    numVotes = \"Number of Votes\"\n  )\n\n\n\n\n\n\n\n\nMost Successful Comedy Movies\n\n\nTitle\nSuccess Score\nAverage Rating\nNumber of Votes\n\n\n\n\nDjango Unchained\n0.9069468\n8.5\n1729019\n\n\nBack to the Future\n0.8982525\n8.5\n1333279\n\n\nThe Wolf of Wall Street\n0.8897217\n8.2\n1620302\n\n\nThe Intouchables\n0.8867587\n8.5\n945572\n\n\nLife Is Beautiful\n0.8842202\n8.6\n754383"
  },
  {
    "objectID": "mp02.html#successful-personnel-in-the-genre",
    "href": "mp02.html#successful-personnel-in-the-genre",
    "title": "Proposing a Successful Film",
    "section": "Successful Personnel in the Genre",
    "text": "Successful Personnel in the Genre\nAs I develop my team, I want to consider the benefits of pairing an older, established actor—someone with over 20 successful titles—to lend credibility and experience, alongside an up-and-coming actor who can bring fresh energy and appeal to a younger audience. This combination can create a dynamic synergy that enhances the project’s overall impact.\nWhen working with NAME_BASICS, I can only have alive personnel on my team. Here, I am creating a new data frame called ALIVE_NAME_BASICS.\n\n\nDisplay Code\nALIVE_NAME_BASICS &lt;- NAME_BASICS |&gt;\n  filter(birthYear &gt;= 1916, is.na(deathYear)) # Can only have alive personnel on my team\nsample_n(ALIVE_NAME_BASICS, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\nI will aso identify titles with a success score greater than 0.6 in SUCCESSFUL_TITLES.\n\n\nDisplay Code\n#Successful Movies Dataset\nSUCCESSFUL_TITLES &lt;- TITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  filter(success_score &gt;= 0.6)\nsample_n(SUCCESSFUL_TITLES, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\nEstablished Drama Actors & Actresses\n\n\nDisplay Code\n# actor\nTITLE_PRINCIPALS |&gt;\n  filter(category == \"actor\") |&gt;\n  filter(tconst %in% SUCCESSFUL_TITLES$tconst) |&gt;\n  select(tconst, nconst) |&gt;\n  inner_join(ALIVE_NAME_BASICS, by = \"nconst\") |&gt;\n  inner_join(SUCCESSFUL_TITLES, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\") |&gt;\n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Drama\") |&gt;\n  group_by(primaryName) |&gt;\n  summarise(\n    success_count = n(),\n    mean_success_score = mean(success_score, na.rm = TRUE)  # Ensure NA values are ignored\n  ) |&gt;\n  filter(success_count &gt;= 20) |&gt;\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(5)|&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Top 5 Drama Actors\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Actor Name\",\n    success_count = \"Success Count\",\n    mean_success_score = \"Mean Success Score\"\n  )\n\n\n\n\n\n\n\n\nTop 5 Drama Actors\n\n\nActor Name\nSuccess Count\nMean Success Score\n\n\n\n\nBrad Pitt\n31\n0.7833171\n\n\nLeonardo DiCaprio\n28\n0.7801242\n\n\nChristian Bale\n38\n0.7641907\n\n\nRyan Gosling\n21\n0.7620046\n\n\nTom Hanks\n38\n0.7595574\n\n\n\n\n\n\n\n\n\nDisplay Code\n# actor\nTITLE_PRINCIPALS |&gt;\n  filter(category == \"actress\") |&gt;\n  filter(tconst %in% SUCCESSFUL_TITLES$tconst) |&gt;\n  select(tconst, nconst) |&gt;\n  inner_join(ALIVE_NAME_BASICS, by = \"nconst\") |&gt;\n  inner_join(SUCCESSFUL_TITLES, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\") |&gt;\n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Drama\") |&gt;\n  group_by(primaryName) |&gt;\n  summarise(\n    success_count = n(),\n    mean_success_score = mean(success_score, na.rm = TRUE)  # Ensure NA values are ignored\n  ) |&gt;\n  filter(success_count &gt;= 20) |&gt;\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(5)|&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Top 5 Drama Actresses\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Actor Name\",\n    success_count = \"Success Count\",\n    mean_success_score = \"Mean Success Score\"\n  )\n\n\n\n\n\n\n\n\nTop 5 Drama Actresses\n\n\nActor Name\nSuccess Count\nMean Success Score\n\n\n\n\nScarlett Johansson\n30\n0.7471914\n\n\nFrances McDormand\n24\n0.7253185\n\n\nEmily Blunt\n23\n0.7252131\n\n\nJessica Chastain\n24\n0.7219137\n\n\nNatalie Portman\n26\n0.7205248"
  },
  {
    "objectID": "mp02.html#up-and-coming-actors-actresses",
    "href": "mp02.html#up-and-coming-actors-actresses",
    "title": "Proposing a Successful Film",
    "section": "Up and Coming Actors & Actresses",
    "text": "Up and Coming Actors & Actresses\nTo find up and coming actors, I tried a couple of ways to define the criteria for “up and coming”. What if we consider mean success score? We could find top scoring actors but with low success counts.\n\n\nDisplay Code\n# actor\nTITLE_PRINCIPALS |&gt;\n  filter(category == \"actor\") |&gt;\n  filter(tconst %in% SUCCESSFUL_TITLES$tconst) |&gt;\n  select(tconst, nconst) |&gt;\n  inner_join(ALIVE_NAME_BASICS, by = \"nconst\") |&gt;\n  inner_join(SUCCESSFUL_TITLES, by = \"tconst\") |&gt;\n  filter(titleType == \"movie\") |&gt;\n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Drama\") |&gt;\n  group_by(primaryName) |&gt;\n  summarise(\n    success_count = n(),\n    mean_success_score = mean(success_score, na.rm = TRUE)  # Ensure NA values are ignored\n  ) |&gt;\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Top Scoring Actors with Low Success Counts\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Actor Name\",\n    success_count = \"Success Count\",\n    mean_success_score = \"Mean Success Score\"\n  )\n\n\n\n\n\n\n\n\nTop Scoring Actors with Low Success Counts\n\n\nActor Name\nSuccess Count\nMean Success Score\n\n\n\n\nMichael Conner Humphreys\n1\n0.9315685\n\n\nJohn Bach\n2\n0.9303864\n\n\nSala Baker\n4\n0.9303610\n\n\nJonathan Sagall\n1\n0.9267397\n\n\nShmuel Levy\n1\n0.9267397\n\n\n\n\n\n\n\nMichael Conner Humphreys has only been in 1 film where he played young Forrest Gump. This does not seem like the best way to define up and coming. I do want someone with a higher success count. What if I limit it to between 5 and 10 successful titles.\n\n\nDisplay Code\nTITLE_PRINCIPALS |&gt;\n  filter(category == \"actor\") |&gt;\n  filter(tconst %in% SUCCESSFUL_TITLES$tconst) |&gt;\n  select(tconst, nconst) |&gt;\n  inner_join(ALIVE_NAME_BASICS, by = \"nconst\") |&gt;\n  inner_join(SUCCESSFUL_TITLES, by = \"tconst\") |&gt;\n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Drama\") |&gt;\n  filter(titleType == \"movie\", startYear &gt;=2020) |&gt;\n  group_by(primaryName) |&gt;\n  summarise(\n    success_count = n(),\n    mean_success_score = mean(success_score, na.rm = TRUE)  # Ensure NA values are ignored\n  ) |&gt;\n  filter(success_count &gt;=5 & success_count &lt;=10) |&gt; # 5 to 10 successful titles\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(10) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Actors with High Success Scores and Between 5-10 Successful Titles Since 2020\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Actress Name\",\n    success_count = \"Success Count\",\n    mean_success_score = \"Mean Success Score\"\n  )\n\n\n\n\n\n\n\n\nActors with High Success Scores and Between 5-10 Successful Titles Since 2020\n\n\nActress Name\nSuccess Count\nMean Success Score\n\n\n\n\nTimothée Chalamet\n5\n0.8000488\n\n\nColin Farrell\n6\n0.7626842\n\n\nSahil Vaid\n5\n0.7508455\n\n\nJeffrey Wright\n5\n0.7449358\n\n\nMark Rylance\n5\n0.7401355\n\n\nAchyuth Kumar\n7\n0.7290892\n\n\nTom Hanks\n7\n0.7270197\n\n\nAjay Devgn\n9\n0.7232701\n\n\nRao Ramesh\n6\n0.7230589\n\n\nJohnny Flynn\n5\n0.7157819\n\n\n\n\n\n\n\nTom Hanks… I don’t think I could consider him an up and coming actor. Let us adjust again. It seems like the startYear lowers the success count. It only counts for recent movies and so established actors show up too because their earlier successes are not counted. Does up and coming mean young or just that their first movie was recent? I think older personell can be up and coming if they are just coming into the scene. Let’s try looking at the minimum start year of their first titles and actors with a number of successes.\n\n\nDisplay Code\nTITLE_PRINCIPALS |&gt;\n  filter(category == \"actor\") |&gt;\n  select(tconst, nconst) |&gt;\n  right_join(ALIVE_NAME_BASICS, by = \"nconst\") |&gt;\n  left_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres == \"Drama\", titleType == \"movie\") |&gt;\n  select(primaryName, primaryTitle, startYear, genres, success_score) |&gt;\n  filter(success_score &gt;= 0.6) |&gt;  # Filter by success score\n  group_by(primaryName) |&gt;  # group by actor\n  summarise(\n    debut_year = min(startYear, na.rm = TRUE),  # Compute first movie they did here\n    success_count = n(), # count succeses \n    mean_success_score = mean(success_score, na.rm = TRUE), # find mean success score\n    .groups = 'drop'\n  ) |&gt;\n  filter(debut_year &gt;= 2015, success_count &gt;= 5 & success_count &lt;= 10) |&gt;\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Up and Coming Actors\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Name\",\n    debut_year = \"Year of First Movie\",\n    success_count = \"Success Count\",\n    mean_success_score = \"Mean Success Score\"\n  )\n\n\n\n\n\n\n\n\nUp and Coming Actors\n\n\nName\nYear of First Movie\nSuccess Count\nMean Success Score\n\n\n\n\nAnthony Ramos\n2018\n5\n0.7734428\n\n\nNoah Jupe\n2017\n7\n0.7565397\n\n\nBarry Keoghan\n2017\n8\n0.7535545\n\n\nDave Bautista\n2015\n7\n0.7352465\n\n\nLeslie Odom Jr.\n2019\n5\n0.7348193\n\n\n\n\n\n\n\nSelecting Anthony Ramos, Noah Jupe, and Barry Keoghan from this list, I would consider them lesser known actors who were a part of successful films."
  },
  {
    "objectID": "mp02.html#combinations-of-personnel",
    "href": "mp02.html#combinations-of-personnel",
    "title": "Proposing a Successful Film",
    "section": "Combinations of Personnel",
    "text": "Combinations of Personnel\nActor/director pairs who have been successful together\n\n\nDisplay Code\n# Filter actors and directors first\nactors_df &lt;- TITLE_PRINCIPALS |&gt;\n  filter(category %in% c(\"actor\", \"actress\")) |&gt;\n  select(tconst, nconst)\n\ndirectors_df &lt;- TITLE_PRINCIPALS |&gt;\n  filter(category == \"director\") |&gt;\n  select(tconst, nconst)\n\n# Join actors and directors to create combinations\nactor_director_pairs &lt;- actors_df |&gt;\n  inner_join(directors_df, by = \"tconst\", suffix = c(\"_actor\", \"_director\"), relationship = \"many-to-many\")\n\nactor_director_names &lt;- actor_director_pairs |&gt;\n  inner_join(ALIVE_NAME_BASICS, by = c(\"nconst_actor\" = \"nconst\"), relationship = \"many-to-many\") |&gt; # join to names\n  rename(actor_name = primaryName) |&gt;\n  inner_join(ALIVE_NAME_BASICS, by = c(\"nconst_director\" = \"nconst\"), relationship = \"many-to-many\") |&gt; # join to names\n  rename(director_name = primaryName) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt; # join with titles\n  inner_join(TITLE_RATINGS, by = \"tconst\") # join with ratings\n\nactor_director_names |&gt; \n  group_by(actor_name, director_name) |&gt; # group by actor_name and director_name combinations\n  summarise(\n    success_count = n(), # count the number of times they've worked together\n    mean_success_score = mean(success_score, na.rm = TRUE)) |&gt; # find the mean success score\n  filter(mean_success_score &gt; 0.60) |&gt;\n  select(actor_name, director_name, success_count, mean_success_score) |&gt;\n  arrange(desc(success_count), desc(mean_success_score)) |&gt;\n  head(10)\n\n\n# A tibble: 10 × 4\n# Groups:   actor_name [10]\n   actor_name       director_name        success_count mean_success_score\n   &lt;chr&gt;            &lt;chr&gt;                        &lt;int&gt;              &lt;dbl&gt;\n 1 Trey Parker      Trey Parker                    888              0.669\n 2 Matt Stone       Trey Parker                    866              0.670\n 3 Masako Nozawa    Daisuke Nishio                 466              0.612\n 4 Hank Azaria      Mark Kirkland                  350              0.615\n 5 Dan Castellaneta Mark Kirkland                  346              0.614\n 6 Mona Marshall    Trey Parker                    338              0.674\n 7 Harry Shearer    Mark Kirkland                  336              0.615\n 8 Sam Marin        John Davis Infantino           301              0.685\n 9 Nancy Cartwright Mark Kirkland                  281              0.614\n10 William Salyers  John Davis Infantino           274              0.688\n\n\nI am getting mostly voice actors in the result above. My guess is this is due to episodes and tv series having a higher count. It may help to filter out the TV episodes. We can see how directors of TV series that work with the same actors multiple times may skew the success count.\n\n\nDisplay Code\nTITLE_BASICS |&gt;\n  group_by(titleType) |&gt;\n  summarize(count = n())\n\n\n# A tibble: 10 × 2\n   titleType     count\n   &lt;chr&gt;         &lt;int&gt;\n 1 movie        131662\n 2 short         16656\n 3 tvEpisode    155722\n 4 tvMiniSeries   5907\n 5 tvMovie       15007\n 6 tvSeries      29789\n 7 tvShort         410\n 8 tvSpecial      3045\n 9 video          9332\n10 videoGame      4668\n\n\nTop 10 Actor/Actress and Director Pairs in Drama Genre\n\n\nDisplay Code\nactor_director_names |&gt; \n  filter(titleType == \"movie\") |&gt; # filter for movies so results are not skewed by number of episodes\n  separate_longer_delim(genres, \",\") |&gt;\n  filter(genres == \"Drama\") |&gt; # filter by Drama\n  group_by(actor_name, director_name) |&gt; # group by actor_name and director_name combinations\n  summarise(\n    success_count = n(), # count the number of times they've worked together\n    mean_success_score = mean(success_score, na.rm = TRUE)) |&gt; # find the mean success score\n  filter(mean_success_score &gt; 0.60, success_count &gt; 5) |&gt;\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(10)\n\n\n# A tibble: 10 × 4\n# Groups:   actor_name [10]\n   actor_name          director_name     success_count mean_success_score\n   &lt;chr&gt;               &lt;chr&gt;                     &lt;int&gt;              &lt;dbl&gt;\n 1 Christian Bale      Christopher Nolan             7              0.913\n 2 Robert De Niro      Martin Scorsese               8              0.809\n 3 Ethan Hawke         Richard Linklater             7              0.766\n 4 Prabhas             S.S. Rajamouli                6              0.757\n 5 Frank Welker        Don Bluth                     6              0.757\n 6 Penélope Cruz       Pedro Almodóvar               6              0.739\n 7 Tony Leung Chiu-wai Kar-Wai Wong                  7              0.735\n 8 Woody Allen         Woody Allen                   7              0.729\n 9 Clint Eastwood      Clint Eastwood               18              0.728\n10 Megumi Hayashibara  Kazuya Tsurumaki             14              0.723\n\n\nWhat if we look at a specific director to see what actors and actresses they work well with. For example, if I wanted Steven Spielberg. Who has he worked well with in the past?\n\n\nDisplay Code\nactor_director_names |&gt; \n  filter(titleType == \"movie\") |&gt; # filter for movies so results are not skewed by number of episodes\n  filter(director_name == \"Steven Spielberg\") |&gt;\n  group_by(actor_name, director_name) |&gt; # group by actor_name and director_name combinations\n  summarise(\n    success_count = n(), # count the number of times they've worked together\n    mean_success_score = mean(success_score, na.rm = TRUE)) |&gt; # find the mean success score\n  select(actor_name, success_count, mean_success_score) |&gt;\n  arrange(desc(success_count), desc(mean_success_score)) |&gt;\n  head(5)\n\n\n# A tibble: 5 × 3\n# Groups:   actor_name [5]\n  actor_name    success_count mean_success_score\n  &lt;chr&gt;                 &lt;int&gt;              &lt;dbl&gt;\n1 Tom Hanks                 5              0.832\n2 Harrison Ford             4              0.830\n3 Mark Rylance              4              0.781\n4 Dan Aykroyd               4              0.669\n5 Simon Pegg                3              0.801\n\n\nNow let’s look at people the director has worked with at least twice.\n\n\nDisplay Code\nactor_director_names |&gt; \n  filter(titleType == \"movie\") |&gt; # filter for movies so results are not skewed by number of episodes\n  filter(director_name == \"Steven Spielberg\") |&gt;\n  group_by(actor_name, director_name) |&gt; # group by actor_name and director_name combinations\n  summarise(\n    success_count = n(), # count the number of times they've worked together\n    mean_success_score = mean(success_score, na.rm = TRUE)) |&gt; # find the mean success score\n  filter(success_count &gt;= 2) |&gt; # worked with multiple times (at least twice)\n  select(actor_name, success_count, mean_success_score) |&gt;\n  arrange(desc(mean_success_score), desc(success_count)) |&gt;\n  head(5) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Actors & Actresses Steven Spielberg Worked With\"\n  ) |&gt;\n  cols_label( # display column names\n    actor_name = \"Actor/Actress\",\n    success_count = \"Success Count\",\n    mean_success_score = \"Mean Success Score\"\n  )  \n\n\n\n\n\n\n\n\nActors & Actresses Steven Spielberg Worked With\n\n\nSuccess Count\nMean Success Score\n\n\n\n\nGiovanni Ribisi\n\n\n2\n0.9076895\n\n\nVic Tablian\n\n\n2\n0.8852299\n\n\nJohn Rhys-Davies\n\n\n2\n0.8761031\n\n\nCaroline Goodall\n\n\n2\n0.8435231\n\n\nTom Hanks\n\n\n5\n0.8319899"
  },
  {
    "objectID": "mp02.html#nostalgia-and-remakes",
    "href": "mp02.html#nostalgia-and-remakes",
    "title": "Proposing a Successful Film",
    "section": "Nostalgia and Remakes",
    "text": "Nostalgia and Remakes\nThe classic movie I propose to remake is The Princess Bride. Remaking The Princess Bride, a classic with an 8 IMDb rating, taps into a well-loved story while allowing us to introduce fresh talent, including original cast cameos, to engage both longtime fans and new audiences. The original has a large number of IMDb ratings, a high average rating, and has not been remade in the past 25 years. A Princess Bride Home Movie was created during COVID, a miniseries shot on phones from home, but a full film remake would be very successful. \n\n\nDisplay Code\nTITLE_BASICS |&gt;\n  filter(primaryTitle == \"The Princess Bride\")|&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  select(primaryTitle, averageRating, numVotes, success_score) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"The Princess Bride\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryTitle = \"Title\",\n    averageRating = \"Average Rating\",\n    numVotes = \"Number of Votes\",\n    success_score = \"Success Score\"\n  )\n\n\n\n\n\n\n\n\nThe Princess Bride\n\n\nTitle\nAverage Rating\nNumber of Votes\nSuccess Score\n\n\n\n\nThe Princess Bride\n8\n456797\n0.8373338\n\n\n\n\n\n\n\nSuccessful Genres The Princess Bride is a film filled with Drama, Action, and Comedy, three of the top performing genres.\n\n\nDisplay Code\nrecent_top_genres &lt;- TITLE_BASICS |&gt;\n  left_join(TITLE_RATINGS, by = \"tconst\") |&gt; \n  filter(success_score &gt;= 0.6) |&gt; \n  separate_longer_delim(genres, \",\") |&gt; \n  filter(genres %in% c(\"Drama\", \"Comedy\", \"Action\")) |&gt;\n  group_by(genres, startYear) |&gt;  # Group by genres and startYear\n  summarise(success_count = n(), .groups = 'drop') |&gt; \n  ungroup() |&gt;\n  arrange(startYear, desc(success_count))\n\n\n\n\nDisplay Code\nggplot(recent_top_genres, aes(x = startYear, y = success_count, fill = genres)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    title = \"Growth of Successful Movies by Genre Over Time\",\n    x = \"Year\",\n    y = \"Count of Successful Movies\",\n    fill = \"Genre\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~ genres, scales = \"free_y\")  # Create separate plots for each genre\n\n\n\n\n\n\n\n\n\nKey Personnel Let’s confirm whether key actors, directors, or writers from the original are still alive.\n\n\nDisplay Code\nTITLE_PRINCIPALS |&gt;\n  filter(tconst == \"tt0093779\") |&gt;\n  inner_join(NAME_BASICS, by = \"nconst\") |&gt;\n  filter(category %in% c(\"actor\", \"actress\", \"director\", \"writer\")) |&gt;\n  select(primaryName, category, characters, deathYear) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Key Personnel\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Name\",\n    category = \"Role\",\n    characters = \"Characters\",\n    deathYear = \"Death Year\"\n  )\n\n\n\n\n\n\n\n\nKey Personnel\n\n\nName\nRole\nCharacters\nDeath Year\n\n\n\n\nCary Elwes\nactor\n[\"Westley\"]\nNA\n\n\nMandy Patinkin\nactor\n[\"Inigo Montoya\"]\nNA\n\n\nRobin Wright\nactress\n[\"The Princess Bride\"]\nNA\n\n\nChristopher Guest\nactor\n[\"Count Rugen\"]\nNA\n\n\nWallace Shawn\nactor\n[\"Vizzini\"]\nNA\n\n\nAndré René Roussimoff\nactor\n[\"Fezzik\"]\n1993\n\n\nFred Savage\nactor\n[\"The Grandson\"]\nNA\n\n\nPeter Falk\nactor\n[\"The Grandfather\"]\n2011\n\n\nPeter Cook\nactor\n[\"The Impressive Clergyman\"]\n1995\n\n\nRob Reiner\ndirector\n\\N\nNA\n\n\nWilliam Goldman\nwriter\n\\N\n2018\n\n\n\n\n\n\n\nProven Director &lt;a\nRenowned for his ability to capture magic in storytelling, Steven Spielberg is ideal for reimagining this beloved classic. With Steven Spielberg, we can get a balance of heartfelt storytelling and commercial success, making this project a compelling remake. His success in genres such as Drama and Action fit well with The Princess Bride.\n\n\nDisplay Code\nNAME_BASICS |&gt;\n  filter(primaryName == 'Steven Spielberg') |&gt;\n  separate_longer_delim(knownForTitles, \",\") |&gt; \n  left_join(TITLE_BASICS, by = c(\"knownForTitles\" = \"tconst\")) |&gt; \n  left_join(TITLE_RATINGS, by = c(\"knownForTitles\" = \"tconst\")) |&gt;\n  select(primaryName, primaryTitle, success_score, averageRating, numVotes) |&gt;\n  arrange(desc(success_score)) |&gt;\n  gt() |&gt; # create a display table\n  tab_header(\n    title = \"Steven Spielberg    Project Scores\"\n  ) |&gt;\n  cols_label( # display column names\n    primaryName = \"Name\",\n    primaryTitle = \"Title\",\n    success_score = \"Success Score\",\n    averageRating = \"Average Rating\",\n    numVotes = \"Number of Votes\"\n  )\n\n\n\n\n\n\n\n\nSteven Spielberg Project Scores\n\n\nName\nTitle\nSuccess Score\nAverage Rating\nNumber of Votes\n\n\n\n\nSteven Spielberg\nSchindler's List\n0.9267397\n9.0\n1475891\n\n\nSteven Spielberg\nSaving Private Ryan\n0.9076895\n8.6\n1521594\n\n\nSteven Spielberg\nRaiders of the Lost Ark\n0.8852299\n8.4\n1049518\n\n\nSteven Spielberg\nE.T. the Extra-Terrestrial\n0.8313398\n7.9\n443655\n\n\n\n\n\n\n\nSteven Spielberg has consistently directed successful movies for over 5 decades.\n\n\nDisplay Code\nspielberg_success &lt;- TITLE_PRINCIPALS |&gt;\nfilter(nconst %in% NAME_BASICS$nconst[NAME_BASICS$primaryName == \"Steven Spielberg\"]) |&gt;\n  inner_join(TITLE_BASICS, by = \"tconst\") |&gt;\n  inner_join(TITLE_RATINGS, by = \"tconst\") |&gt;\n  select(primaryTitle, startYear, success_score) |&gt;\n  distinct() |&gt;  # Remove duplicates\n  mutate(successful = ifelse(success_score &gt;= 0.6, 1, 0)) |&gt;\n  group_by(startYear) |&gt;\n  summarise(success_count = sum(successful), .groups = 'drop') |&gt;\n  filter(success_count &gt; 0) |&gt;  # Only keep years with successful films\n  arrange(startYear)\n\n\n\n\nDisplay Code\n# Plotting\nggplot(spielberg_success, aes(x = startYear, y = success_count)) +\n  geom_line(color = \"blue\", size = .5) +\n  geom_point(color = \"blue\", size = 1) +\n  labs(title = \"Number of Successful Films Directed by Steven Spielberg Over Time\",\n       x = \"Year\",\n       y = \"Number of Successful Films\") +\n  scale_y_continuous(limits = c(0, NA)) +  # Set y-axis to start at 0\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCasting The original actress, Robin Wright, who played The Princess Bride has previously worked with Tom Hanks in the successful film Forrest Gump. However, it might be a good idea to cast some up and coming actors and actresses as leads to attract newer audience. We can keep Wallace Shawn as Vizzini for fans and a nod towards the original classic. By casting Mille Bobby Brown as The Princess Bride and Noah Jupe as Westley. Noah is known for his performances in A Quiet Place and Honey Boy, Jupe brings a fresh energy and charm suitable for the role of Westley. Timothée Chalamet could be cast as Inigo Montoya. His performances in Dune: Part Two and Part One make him an excellent choice for the iconic role of Inigo, seeking vengeance for his father."
  },
  {
    "objectID": "mp02.html#elevator-pitch",
    "href": "mp02.html#elevator-pitch",
    "title": "Proposing a Successful Film",
    "section": "Elevator Pitch",
    "text": "Elevator Pitch\nFrom the visionary mind of Steven Spielberg comes a timeless tale of adventure and romance, The Princess Bride. Featuring the talented Noah Jupe as Westley and the dynamic Millie Bobby Brown as Buttercup, this re-imagining will delight both old fans and new. With Timothée Chalamet as the iconic Inigo Montoya and Wallace Shawn reprising his role as Vizzini, alongside the incredible Julianne Moore, this film is a story of love, bravery, and the magic of storytelling—coming soon to theaters near you!\nThis remake promises to capture the heart of the original while inviting audiences into a fresh, enchanting cinematic experience."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cindy Li",
    "section": "",
    "text": "Hi! I’m Cindy. Welcome to my page of projects!\nI am a Data Analyst based in NYC currently pursuing my Master’s in Business Analytics with a concentration in Data Analysis.\n\n\nA little about me…\n\nPreviously a Business Analyst at Bank of America\nBoston College Alumna (majored in Management Information Systems and Business Analytics, with a minor in Computer Science)\nLived in 3 countries\nSwiftie! Taylor Swift followed me on tumblr.\nI love to sew and am passionate about sustainable fashion and how technology can reduce the environmental/social impacts of the fashion industry.\n\n\n\nCurrently learning:\n\nR (Software Tools for Data Analysis)\nPython (Programming for Analytics)\nSQL (Principles of Database Management Systems)\nSalsa & bachata\n\n\nLet’s Connect!"
  },
  {
    "objectID": "mp03.html",
    "href": "mp03.html",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "",
    "text": "The U.S. Electoral College (EC) system, by design, has a significant impact on presidential elections, often making the distribution of votes much more complex than a simple nationwide popular vote. The system has been debated, especially when the results diverge from the popular vote. This analysis’ primary goal is to assess how the allocation schemes impact the election outcomes and whether any bias exists, especially in favor of one political party."
  },
  {
    "objectID": "mp03.html#data-i-election-data",
    "href": "mp03.html#data-i-election-data",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data I: ELection Data",
    "text": "Data I: ELection Data\nData Source: MIT Election Data Science Lab datasets From the MIT Election Data Science Lab, we are retrieving two data sets. First, are votes from all biennial congressional races in all 50 states from 1976 to 2020. Second, are statewide presidential vote cotes. This requires a download from the link\n\n\nCode\nif (!require(\"readr\")) install.packages(\"readr\")\nif (!require(\"sf\")) install.packages(\"sf\")\nif (!require(\"dplyr\")) install.packages(\"dplyr\")\nif (!require(\"tidyr\")) install.packages(\"tidyr\")\nif (!require(\"tidyverse\")) install.packages(\"tidyverse\")\nif (!require(\"DT\")) install.packages(\"DT\")\nif (!require(\"ggplot2\")) install.packages(\"ggplot2\")\nlibrary(readr)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(ggplot2)\nlibrary(gt)\n\n\n\n1976-2022 House Data\n\n\nCode\nHOUSE &lt;- read_csv(\"1976-2022-house.csv\")\nPRESIDENT &lt;- read_csv(\"1976-2020-president.csv\")\n\nsample_n(HOUSE, 1000) |&gt;\n  DT::datatable()\n\n\n\n\n\n\n\n\n1976-2020 President Data\n\n\nCode\nsample_n(HOUSE, 1000) |&gt;\n  DT::datatable()"
  },
  {
    "objectID": "mp03.html#data-ii-congressional-boundary-files-1976-to-2012",
    "href": "mp03.html#data-ii-congressional-boundary-files-1976-to-2012",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data II: Congressional Boundary Files 1976 to 2012",
    "text": "Data II: Congressional Boundary Files 1976 to 2012\nData Source: Jeffrey B. Lewis, Brandon DeVine, and Lincoln Pritcher with Kenneth C. Martis This source give us the shapefiles for all US congressional districts from 1789 to 2012.\n\n\nCode\nget_file &lt;- function(fname){\n  BASE_URL &lt;- \"https://cdmaps.polisci.ucla.edu/shp/\"\n  fname_ext &lt;- paste0(fname, \".zip\")\n  fname_ext1 &lt;- paste0(fname, \".shp\")\n  fname_extunzip &lt;- gsub(\".zip$\", \"\", fname_ext)\n  subfolder &lt;- \"districtshapes\"  # Subfolder where the shapefile is located\n  if(!file.exists(fname_ext)){\n    FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n    download.file(FILE_URL, \n                  destfile = fname_ext)\n  }\n  # Unzip the contents and save unzipped content\n  unzip(zipfile = fname_ext, exdir = fname_extunzip)\n  # Define File Path\n  shapefile_path &lt;- file.path(fname_extunzip, subfolder, fname_ext1)\n  # Read the shapefile\n  read_sf(shapefile_path)\n}\n\n# Download files by iterating through\nstart_congress = 95\nend_congress = 114\nfor (i in start_congress:end_congress) {\n  district_name &lt;- sprintf(\"districts%03d\", i)  # Formats as district001, district002, etc.\n  district_data &lt;- get_file(district_name)   # Download and read the shapefile\n  assign(district_name, district_data, envir = .GlobalEnv)  # Assign the data frame to a variable in the global environment\n}"
  },
  {
    "objectID": "mp03.html#data-iii-congressional-boundary-files-2014-to-present",
    "href": "mp03.html#data-iii-congressional-boundary-files-2014-to-present",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Data III: Congressional Boundary Files 2014 to Present",
    "text": "Data III: Congressional Boundary Files 2014 to Present\nData Source: US Census Bureau This data source provides district boundaries for more recent congressional elections.\n\n\nCode\nget_congress_file &lt;- function(fname, year){\n  BASE_URL &lt;- sprintf(\"https://www2.census.gov/geo/tiger/TIGER%d/CD/\", year) #replace %d with year\n  fname_ext &lt;- paste0(fname, \".zip\")\n  fname_ext1 &lt;- paste0(fname, \".shp\")\n  fname_extunzip &lt;- gsub(\".zip$\", \"\", fname_ext)\n  \n  # Download File\n  if(!file.exists(fname_ext)){\n    FILE_URL &lt;- paste0(BASE_URL, fname_ext)\n    download.file(FILE_URL, \n                  destfile = fname_ext)\n  }\n  # Unzip the contents and save unzipped content\n  unzip(zipfile = fname_ext, exdir = fname_extunzip)\n  # Define File Path\n  shapefile_path &lt;- file.path(fname_extunzip, fname_ext1)\n  # Read the shapefile\n  read_sf(shapefile_path)\n}\n\n# Download file for each district by iterating through each year\nbase_year = 2022\nbase_congress = 116  # Congress number for 2012\nfor (i in 0:10) {  # i will range from 0 (2022) to 10 (2012)\n  year &lt;- base_year - i\n  if (year &gt;= 2018) {congress &lt;- 116} \n  else if (year &gt;= 2016) {congress &lt;- 115} \n  else if (year &gt;= 2014) {congress &lt;- 114} \n  else if (year == 2013) {congress &lt;- 113} \n  else if (year == 2012) {congress &lt;- 112}\n  district_name &lt;- sprintf(\"tl_%d_us_cd%d\", year, congress)\n  district_data &lt;- get_congress_file(district_name, year)  # Download and read the shapefile\n  assign(district_name, district_data, envir = .GlobalEnv)  # Assign the data frame to a variable in the global environment\n  }"
  },
  {
    "objectID": "mp03.html#maps-shapefiles",
    "href": "mp03.html#maps-shapefiles",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "Maps & Shapefiles",
    "text": "Maps & Shapefiles\n\nChloropleth Visualization of the 2000 Presidential Election Electoral College Results\nFilter Election Data for 2000: To create a map of the results broken down by states, we will need to find the election results of each state. The first step involves filtering the election dataset PRESIDENT to get the results for the year 2000. We specifically focus on the U.S. Presidential election and filter for the two main candidates, George W. Bush and Al Gore. We then calculate the winner for each state based on who received the most votes and assign the appropriate party.\n\n\nCode\nelection_2000 &lt;- PRESIDENT |&gt;\n  filter(year == 2000, office == \"US PRESIDENT\") |&gt; # filter for 2000 and president office\n  filter(candidate %in% c(\"BUSH, GEORGE W.\", \"GORE, AL\")) |&gt; # filter for Bush and Gore\n  group_by(state) |&gt;\n  summarise( # Winner based on the candidate with the most votes\n    winner = if_else(sum(candidatevotes[candidate == \"BUSH, GEORGE W.\"]) &gt; sum(candidatevotes[candidate == \"GORE, AL\"]),\n      \"Bush\", \"Gore\"),\n    winner_party = case_when(# Party based on the candidate\n      winner == \"Bush\" ~ \"Republican\",\n      winner == \"Gore\" ~ \"Democrat\"\n    )) |&gt;\n  ungroup()\n\n\nJoin Election Data with Shapefiles: The next step is to join the election results with the geographical shapefile data. This step ensures that we can visualize the election results on a map by linking the state names in both datasets. The shapefile data is modified to ensure the state names are in uppercase to match the election data. After merging the data, we create a choropleth map of the contiguous U.S. states. We use geom_sf() to plot the states and color them based on the winning party (Republican or Democrat). The map is then customized to remove axis labels and grid lines for a clean visualization.\n\n\nCode\n# join with shapefile\ndistricts106$STATENAME &lt;- toupper(districts106$STATENAME) # uppercase state name to match\n\ndis_election_2000 &lt;- left_join(districts106, election_2000, by = c(\"STATENAME\" = \"state\"), relationship = \"many-to-many\")\n\nmain_us &lt;- dis_election_2000 |&gt; filter(!STATENAME %in% c(\"ALASKA\", \"HAWAII\"))\n\nggplot(main_us, aes(geometry = geometry, fill = winner_party)) +\n  geom_sf() + \n  scale_fill_manual(values = c(\"Republican\" = \"red\", \"Democrat\" = \"blue\")) +\n  theme_minimal() +\n  labs(title = \"U.S. Presidential Election Results by State in 2000\",\n       fill = \"Winning Party\") +\n  theme(\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank()\n  ) \n\n\n\n\n\n\n\n\n\nAdd Insets for Alaska and Hawaii: Because Alaska and Hawaii are geographically distant from the mainland U.S., we create insets for these two states. The data for Alaska and Hawaii is filtered separately, and individual maps are created for each. These insets are then added to the main U.S. map.\n\n\nCode\n# contiguous US \nmain_us &lt;- dis_election_2000 |&gt; filter(!STATENAME %in% c(\"ALASKA\", \"HAWAII\"))\nmap_us &lt;- ggplot(main_us, aes(geometry = geometry, fill = winner_party)) +\n  geom_sf() + \n  scale_fill_manual(values = c(\"Republican\" = \"red\", \"Democrat\" = \"blue\")) +\n  theme_minimal() +\n  labs(title = \"U.S. Presidential Election Results by State in 2000\",\n       fill = \"Winning Party\") +\n  theme_void() +\n  coord_sf(xlim = c(-130, -60), ylim = c(20, 50), expand = FALSE) \n\n# filter data for Alaska and Hawaii\nalaska &lt;- dis_election_2000 |&gt; filter(STATENAME == \"ALASKA\")\nhawaii &lt;- dis_election_2000 |&gt; filter(STATENAME == \"HAWAII\")\n\n# Alaska Inset\ninset_alaska &lt;- ggplot(alaska, aes(geometry = geometry, fill = winner_party)) +\n  geom_sf() +\n  scale_fill_manual(values = c(\"Republican\" = \"red\", \"Democrat\" = \"blue\")) +\n  theme_void() +\n  theme(legend.position = \"none\") + \n  coord_sf(xlim = c(-180, -140), ylim = c(50, 72), expand = FALSE)\n\n# Hawaii Inset\ninset_hawaii &lt;- ggplot(hawaii, aes(geometry = geometry, fill = winner_party)) +\n  geom_sf() +\n  scale_fill_manual(values = c(\"Republican\" = \"red\", \"Democrat\" = \"blue\")) +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  coord_sf(xlim = c(-161, -154), ylim = c(18, 23), expand = FALSE)\n\n# Combine Maps\ncombined_map &lt;- map_us +\n  annotation_custom(ggplotGrob(inset_alaska),\n                    xmin = -120, xmax = -130, # position\n                    ymin = 15, ymax = 40) +  # size\n  annotation_custom(ggplotGrob(inset_hawaii),\n                    xmin = -115, xmax = -100, # position\n                    ymin = 20, ymax = 30)    # size\nprint(combined_map)\n\n\n\n\n\n\n\n\n\n\n\nChloropleth Visualization of Electoral College Results Over Time\nData Preparation First, we need to clean the data to ensure they join properly. First, we convert to the same CRS. Then, I am adding a STATENAME column based on the STATEFP as well as changing STATENAME values to uppercase to match.\n\n\nCode\n# convert to the same crs\ndistricts095 &lt;- st_transform(districts095, crs = st_crs(districts112))\ndistricts097 &lt;- st_transform(districts097, crs = st_crs(districts112))\ndistricts098 &lt;- st_transform(districts098, crs = st_crs(districts112))\ndistricts101 &lt;- st_transform(districts101, crs = st_crs(districts112))\ndistricts102 &lt;- st_transform(districts102, crs = st_crs(districts112))\ndistricts103 &lt;- st_transform(districts103, crs = st_crs(districts112))\ndistricts106 &lt;- st_transform(districts106, crs = st_crs(districts112))\ndistricts108 &lt;- st_transform(districts108, crs = st_crs(districts112))\ndistricts111 &lt;- st_transform(districts111, crs = st_crs(districts112))\ntl_2016_us_cd115 &lt;- st_transform(tl_2016_us_cd115, crs = st_crs(districts112))\ntl_2020_us_cd116 &lt;- st_transform(tl_2020_us_cd116, crs = st_crs(districts112))\n\n# convert state names for to uppercase join\ndistricts095$STATENAME &lt;- toupper(districts095$STATENAME)  \ndistricts097$STATENAME &lt;- toupper(districts097$STATENAME)  \ndistricts098$STATENAME &lt;- toupper(districts098$STATENAME)  \ndistricts101$STATENAME &lt;- toupper(districts101$STATENAME)  \ndistricts102$STATENAME &lt;- toupper(districts102$STATENAME)  \ndistricts103$STATENAME &lt;- toupper(districts103$STATENAME)  \ndistricts106$STATENAME &lt;- toupper(districts106$STATENAME)  \ndistricts108$STATENAME &lt;- toupper(districts108$STATENAME)  \ndistricts111$STATENAME &lt;- toupper(districts111$STATENAME)  \ndistricts112$STATENAME &lt;- toupper(districts112$STATENAME)  \n\n# add STATENAME column using statefp\n# https://www.mercercountypa.gov/dps/state_fips_code_listing.htm \ntl_2020_us_cd116 &lt;- tl_2020_us_cd116 |&gt;\n  mutate(STATENAME = case_when(\n    STATEFP == \"01\" ~ \"ALABAMA\",\n    STATEFP == \"02\" ~ \"ALASKA\",\n    STATEFP == \"04\" ~ \"ARIZONA\",\n    STATEFP == \"05\" ~ \"ARKANSAS\",\n    STATEFP == \"06\" ~ \"CALIFORNIA\",\n    STATEFP == \"08\" ~ \"COLORADO\",\n    STATEFP == \"09\" ~ \"CONNECTICUT\",\n    STATEFP == \"10\" ~ \"DELAWARE\",\n    STATEFP == \"11\" ~ \"DISTRICT OF COLUMBIA\",\n    STATEFP == \"12\" ~ \"FLORIDA\",\n    STATEFP == \"13\" ~ \"GEORGIA\",\n    STATEFP == \"15\" ~ \"HAWAII\",\n    STATEFP == \"16\" ~ \"IDAHO\",\n    STATEFP == \"17\" ~ \"ILLINOIS\",\n    STATEFP == \"18\" ~ \"INDIANA\",\n    STATEFP == \"19\" ~ \"IOWA\",\n    STATEFP == \"20\" ~ \"KANSAS\",\n    STATEFP == \"21\" ~ \"KENTUCKY\",\n    STATEFP == \"22\" ~ \"LOUISIANA\",\n    STATEFP == \"23\" ~ \"MAINE\",\n    STATEFP == \"24\" ~ \"MARYLAND\",\n    STATEFP == \"25\" ~ \"MASSACHUSETTS\",\n    STATEFP == \"26\" ~ \"MICHIGAN\",\n    STATEFP == \"27\" ~ \"MINNESOTA\",\n    STATEFP == \"28\" ~ \"MISSISSIPPI\",\n    STATEFP == \"29\" ~ \"MISSOURI\",\n    STATEFP == \"30\" ~ \"MONTANA\",\n    STATEFP == \"31\" ~ \"NEBRASKA\",\n    STATEFP == \"32\" ~ \"NEVADA\",\n    STATEFP == \"33\" ~ \"NEW HAMPSHIRE\",\n    STATEFP == \"34\" ~ \"NEW JERSEY\",\n    STATEFP == \"35\" ~ \"NEW MEXICO\",\n    STATEFP == \"36\" ~ \"NEW YORK\",\n    STATEFP == \"37\" ~ \"NORTH CAROLINA\",\n    STATEFP == \"38\" ~ \"NORTH DAKOTA\",\n    STATEFP == \"39\" ~ \"OHIO\",\n    STATEFP == \"40\" ~ \"OKLAHOMA\",\n    STATEFP == \"41\" ~ \"OREGON\",\n    STATEFP == \"42\" ~ \"PENNSYLVANIA\",\n    STATEFP == \"44\" ~ \"RHODE ISLAND\",\n    STATEFP == \"45\" ~ \"SOUTH CAROLINA\",\n    STATEFP == \"46\" ~ \"SOUTH DAKOTA\",\n    STATEFP == \"47\" ~ \"TENNESSEE\",\n    STATEFP == \"48\" ~ \"TEXAS\",\n    STATEFP == \"49\" ~ \"UTAH\",\n    STATEFP == \"50\" ~ \"VERMONT\",\n    STATEFP == \"51\" ~ \"VIRGINIA\",\n    STATEFP == \"53\" ~ \"WASHINGTON\",\n    STATEFP == \"54\" ~ \"WEST VIRGINIA\",\n    STATEFP == \"55\" ~ \"WISCONSIN\",\n    STATEFP == \"56\" ~ \"WYOMING\"\n  ))\n\ntl_2016_us_cd115 &lt;- tl_2016_us_cd115 |&gt;\n  mutate(STATENAME = case_when(\n    STATEFP == \"01\" ~ \"ALABAMA\",\n    STATEFP == \"02\" ~ \"ALASKA\",\n    STATEFP == \"04\" ~ \"ARIZONA\",\n    STATEFP == \"05\" ~ \"ARKANSAS\",\n    STATEFP == \"06\" ~ \"CALIFORNIA\",\n    STATEFP == \"08\" ~ \"COLORADO\",\n    STATEFP == \"09\" ~ \"CONNECTICUT\",\n    STATEFP == \"10\" ~ \"DELAWARE\",\n    STATEFP == \"11\" ~ \"DISTRICT OF COLUMBIA\",\n    STATEFP == \"12\" ~ \"FLORIDA\",\n    STATEFP == \"13\" ~ \"GEORGIA\",\n    STATEFP == \"15\" ~ \"HAWAII\",\n    STATEFP == \"16\" ~ \"IDAHO\",\n    STATEFP == \"17\" ~ \"ILLINOIS\",\n    STATEFP == \"18\" ~ \"INDIANA\",\n    STATEFP == \"19\" ~ \"IOWA\",\n    STATEFP == \"20\" ~ \"KANSAS\",\n    STATEFP == \"21\" ~ \"KENTUCKY\",\n    STATEFP == \"22\" ~ \"LOUISIANA\",\n    STATEFP == \"23\" ~ \"MAINE\",\n    STATEFP == \"24\" ~ \"MARYLAND\",\n    STATEFP == \"25\" ~ \"MASSACHUSETTS\",\n    STATEFP == \"26\" ~ \"MICHIGAN\",\n    STATEFP == \"27\" ~ \"MINNESOTA\",\n    STATEFP == \"28\" ~ \"MISSISSIPPI\",\n    STATEFP == \"29\" ~ \"MISSOURI\",\n    STATEFP == \"30\" ~ \"MONTANA\",\n    STATEFP == \"31\" ~ \"NEBRASKA\",\n    STATEFP == \"32\" ~ \"NEVADA\",\n    STATEFP == \"33\" ~ \"NEW HAMPSHIRE\",\n    STATEFP == \"34\" ~ \"NEW JERSEY\",\n    STATEFP == \"35\" ~ \"NEW MEXICO\",\n    STATEFP == \"36\" ~ \"NEW YORK\",\n    STATEFP == \"37\" ~ \"NORTH CAROLINA\",\n    STATEFP == \"38\" ~ \"NORTH DAKOTA\",\n    STATEFP == \"39\" ~ \"OHIO\",\n    STATEFP == \"40\" ~ \"OKLAHOMA\",\n    STATEFP == \"41\" ~ \"OREGON\",\n    STATEFP == \"42\" ~ \"PENNSYLVANIA\",\n    STATEFP == \"44\" ~ \"RHODE ISLAND\",\n    STATEFP == \"45\" ~ \"SOUTH CAROLINA\",\n    STATEFP == \"46\" ~ \"SOUTH DAKOTA\",\n    STATEFP == \"47\" ~ \"TENNESSEE\",\n    STATEFP == \"48\" ~ \"TEXAS\",\n    STATEFP == \"49\" ~ \"UTAH\",\n    STATEFP == \"50\" ~ \"VERMONT\",\n    STATEFP == \"51\" ~ \"VIRGINIA\",\n    STATEFP == \"53\" ~ \"WASHINGTON\",\n    STATEFP == \"54\" ~ \"WEST VIRGINIA\",\n    STATEFP == \"55\" ~ \"WISCONSIN\",\n    STATEFP == \"56\" ~ \"WYOMING\"\n  ))\n\n\nCreating a Systematic Election Data Function for Visualization In this section, I have created a function that systematically processes U.S. Presidential election data for each election year. The function takes as input the election year and the corresponding shapefile data and returns a prepared dataset. This allows for easy handling of election data from multiple years, and it can be used to visualize and analyze the results for any given year.\nThe create_election_data takes two arguments: - election_year: the specific year of the presidential election (e.g., 2000, 2004, etc.). - shapefile_data: the shapefile containing the geographical data for that election year. and it returns: - all_election_simplified: the merged dataset, which includes both the election results and the shapefile data.\n\n\nCode\n# Function to create election data\ncreate_election_data &lt;- function(election_year, shapefile_data) {\n  # Step 1: Filter for the specific year and the simplified party\n  election_data &lt;- PRESIDENT |&gt;\n    filter(year == election_year, office == \"US PRESIDENT\") |&gt;  # Filter for the specific year and presidential election\n    filter(party_simplified %in% c(\"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n    group_by(state, state_fips, year) |&gt;  # Group by state and party\n    summarise(\n      winner_party = if_else(sum(candidatevotes[party_simplified == \"DEMOCRAT\"]) &gt; sum(candidatevotes[party_simplified == \"REPUBLICAN\"]),\n                             \"DEMOCRAT\", \"REPUBLICAN\")) |&gt;\n    ungroup() |&gt; \n    filter(!is.na(winner_party))\n  \n  # Step 2: Join with the shapefile data\n  dis_election &lt;- left_join(shapefile_data, election_data, by = c(\"STATENAME\" = \"state\"), relationship = \"many-to-many\")\n  #dis_election$year &lt;- year # add year column\n  return(dis_election)\n}\n# bind election data for each year into one file\nall_election_data &lt;- bind_rows(\n  election_data_2020 &lt;- create_election_data(2020, tl_2020_us_cd116),\n  election_data_2016 &lt;- create_election_data(2016, tl_2016_us_cd115),\n  election_data_2012 &lt;- create_election_data(2012, districts112),\n  election_data_2008 &lt;- create_election_data(2008, districts111),\n  election_data_2004 &lt;- create_election_data(2004, districts108),\n  election_data_2000 &lt;- create_election_data(2000, districts106),\n  election_data_1996 &lt;- create_election_data(1996, districts103),\n  election_data_1992 &lt;- create_election_data(1992, districts102),\n  election_data_1988 &lt;- create_election_data(1988, districts101),\n  election_data_1984 &lt;- create_election_data(1984, districts098),\n  election_data_1980 &lt;- create_election_data(1980, districts097),\n  election_data_1976 &lt;- create_election_data(1976, districts095)\n)\n\n# simplify map data\nsf::sf_use_s2(FALSE)\nall_election_simplified &lt;- st_simplify(all_election_data, dTolerance = 0.01)\n\n\nCreating the Election Results Map With the combined and simplified election data, we can now create a series of maps to visualize the election results for each year. The code below creates a map of the contiguous U.S. (excluding Alaska and Hawaii).\n\n\nCode\nall_alaska &lt;- all_election_simplified |&gt; filter(STATENAME == \"ALASKA\")\nall_hawaii &lt;- all_election_simplified |&gt; filter(STATENAME == \"HAWAII\") \nall_main_us &lt;- all_election_simplified |&gt; filter(!STATENAME %in% c(\"ALASKA\", \"HAWAII\"), !is.na(winner_party))\n  \n  # Step 3: Main map for the contiguous U.S.\nall_map_us &lt;- ggplot(all_main_us, aes(geometry = geometry, fill = winner_party)) +\n  geom_sf() + \n  scale_fill_manual(values = c(\"REPUBLICAN\" = \"red\", \"DEMOCRAT\" = \"blue\")) +\n  theme_minimal() +\n  labs(title = \"U.S. Presidential Election Results by State and Year\",\n       fill = \"Winning Party\") +\n  theme_void() +\n  facet_wrap(~ year, ncol=3) \n\nprint(all_map_us)"
  },
  {
    "objectID": "mp03.html#state-wide-winner-take-all",
    "href": "mp03.html#state-wide-winner-take-all",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "State-Wide Winner-Take-All",
    "text": "State-Wide Winner-Take-All\nn this system, the candidate who wins the most votes in a state receives all of that state’s Electoral College votes, regardless of the margin of victory. In most states (except Nebraska and Maine), if Candidate A wins 51% of the vote in a state, they will receive all of that state’s Electoral Votes, even if Candidate B got 49% of the vote. Each state has a certain number of electoral votes (ECVs), based on its representation in Congress (Senators + House Representatives). Under this system, only the winner of the popular vote in the state gets those votes.\n\n\nCode\nstate_wide_winner_take_all &lt;- PRESIDENT |&gt;\n  group_by(state, year) |&gt;\n  filter(candidatevotes == max(candidatevotes)) |&gt;\n  left_join(ECV, by = c(\"state\" = \"state\", \"year\" = \"year\")) |&gt;\n  select(state, year, candidate, party_simplified, ecv) |&gt;\n  filter(!is.na(ecv))\n\nstate_wide_winner_take_all &lt;- state_wide_winner_take_all |&gt; \n  group_by(year, candidate, party_simplified) |&gt; \n  summarise(total_ecv = sum(ecv), .groups = \"drop\") |&gt; # total ecv\n  arrange(year, total_ecv) |&gt; \n  group_by(year) |&gt; \n  mutate(winner = if_else(total_ecv == max(total_ecv), \"Yes\", \"No\")) |&gt;  # Mark winner\n  ungroup() |&gt;\n  arrange(year, party_simplified)\n\nstate_wide_winner_take_all |&gt; gt() |&gt;\n  tab_header(\n    title = \"State-Wide Winner-Take-All\"\n  ) |&gt;\n  cols_label( # display column names\n    year = \"Year\",\n    candidate = \"Candidate\",\n    party_simplified = \"Party\",\n    total_ecv = \"Electoral Votes\",\n    winner = \"Winning Candidate\"\n  )\n\n\n\n\n\n\n\n\nState-Wide Winner-Take-All\n\n\nYear\nCandidate\nParty\nElectoral Votes\nWinning Candidate\n\n\n\n\n1976\nCARTER, JIMMY\nDEMOCRAT\n294\nYes\n\n\n1976\nFORD, GERALD\nREPUBLICAN\n241\nNo\n\n\n1980\nCARTER, JIMMY\nDEMOCRAT\n87\nNo\n\n\n1980\nREAGAN, RONALD\nREPUBLICAN\n448\nYes\n\n\n1984\nMONDALE, WALTER\nDEMOCRAT\n10\nNo\n\n\n1984\nREAGAN, RONALD\nREPUBLICAN\n525\nYes\n\n\n1988\nDUKAKIS, MICHAEL\nDEMOCRAT\n109\nNo\n\n\n1988\nBUSH, GEORGE H.W.\nREPUBLICAN\n426\nYes\n\n\n1992\nCLINTON, BILL\nDEMOCRAT\n367\nYes\n\n\n1992\nBUSH, GEORGE H.W.\nREPUBLICAN\n168\nNo\n\n\n1996\nCLINTON, BILL\nDEMOCRAT\n376\nYes\n\n\n1996\nDOLE, ROBERT\nREPUBLICAN\n159\nNo\n\n\n2000\nGORE, AL\nDEMOCRAT\n264\nNo\n\n\n2000\nBUSH, GEORGE W.\nREPUBLICAN\n271\nYes\n\n\n2004\nKERRY, JOHN\nDEMOCRAT\n249\nNo\n\n\n2004\nBUSH, GEORGE W.\nREPUBLICAN\n286\nYes\n\n\n2008\nOBAMA, BARACK H.\nDEMOCRAT\n361\nYes\n\n\n2008\nMCCAIN, JOHN\nREPUBLICAN\n174\nNo\n\n\n2012\nOBAMA, BARACK H.\nDEMOCRAT\n329\nYes\n\n\n2012\nROMNEY, MITT\nREPUBLICAN\n206\nNo\n\n\n2016\nCLINTON, HILLARY\nDEMOCRAT\n230\nNo\n\n\n2016\nTRUMP, DONALD J.\nREPUBLICAN\n305\nYes\n\n\n2020\nBIDEN, JOSEPH R. JR\nDEMOCRAT\n306\nYes\n\n\n2020\nTRUMP, DONALD J.\nREPUBLICAN\n232\nNo\n\n\n\n\n\n\n\n\n\nCode\nggplot(state_wide_winner_take_all, aes(x = factor(year), y = total_ecv, fill = party_simplified)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  #  keeps bars side-by-side\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  theme_minimal() +\n  labs(\n    title = \"Total ECV Votes for Each Candidate in U.S. Presidential Elections\",\n    x = \"Year\",\n    y = \"Total ECV\",\n    fill = \"Party\"\n  )"
  },
  {
    "objectID": "mp03.html#district-wide-winner-take-all-state-wide-at-large-votes",
    "href": "mp03.html#district-wide-winner-take-all-state-wide-at-large-votes",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "District-Wide Winner-Take-All + State-Wide “At Large” Votes",
    "text": "District-Wide Winner-Take-All + State-Wide “At Large” Votes\nThis method allocates R ECVs to popular vote winner by congressional district and the remaining 2 ECVs to the state-wide popular vote winner. The hybrid system is used in Maine and Nebraska. In each congressional district, the candidate who wins the popular vote gets one electoral vote. Then, the state as a whole gives two additional “at-large” ECVs to the candidate who wins the overall state-wide popular vote. In Nebraska, if Candidate A wins three of the state’s districts, and Candidate B wins the other district and the statewide popular vote, the electoral votes might be split like this: - Candidate A: 3 ECVs from the districts. - Candidate B: 2 ECVs for winning the state-wide vote. This system allows for a split in how ECVs are allocated, unlike the traditional winner-take-all system where the candidate winning the state by a narrow margin would still receive all the state’s votes.\n\n\nCode\n# look at statewide winner - assign 2 ecv\nstate_wide_winner &lt;- PRESIDENT |&gt;\n  group_by(state, year) |&gt;\n  mutate(statewide_winner = if_else(candidatevotes == max(candidatevotes), \"Yes\", \"No\")) |&gt;  # Mark statewide winner\n  ungroup() |&gt;\n  # Assign ECV based on who won the state\n  mutate(ECV = if_else(statewide_winner == \"Yes\", 2, 0)) |&gt; # assign the 2 ECV if statewide winner, else 0 ECV\n  select(state, year, candidate, candidatevotes, ECV) |&gt;\n  filter(!is.na(candidate))\n\n# look at winner of district - assign 1 ecv per district\n# Assume that the presidential candidate of the same party as the congressional representative wins that election.\n# Find the winner of each district in the HOUSE dataset\ndistrict_winners &lt;- HOUSE |&gt;\n  filter(year %in% c(\"1976\", \"1980\", \"1984\", \"1988\", \"1992\", \"1996\", \"2000\", \"2004\", \"2008\", \"2012\", \"2016\", \"2020\")) |&gt;\n  group_by(state, year, district) |&gt;\n  filter(candidatevotes == max(candidatevotes)) |&gt;\n  ungroup() |&gt;\n  mutate(ecv = 1)  # Assign 1 ECV for each winning district\n\n# Join the district winners with the PRESIDENT dataset to match the party\necv_assignment &lt;- district_winners |&gt;\n  left_join(PRESIDENT, by = c(\"state\", \"year\", \"party\" = \"party_simplified\"), relationship = \"many-to-many\") |&gt;\n  mutate(ecv_presidential = 1) |&gt;\n  select(state, year, district, candidate.y, party, ecv_presidential)\n\n#  Find total ecv from districts\ndistrict_ecv_summary &lt;- ecv_assignment |&gt;\n  group_by(state, year, candidate.y, party) |&gt;\n  summarise(district_total_ecv = sum(ecv_presidential), .groups = \"drop\")\n\n#  Join the district-level ECV summary with the statewide ECVs\necv_combined &lt;- state_wide_winner |&gt;\n  left_join(district_ecv_summary, by = c(\"state\", \"year\", \"candidate\" = \"candidate.y\")) |&gt;\n  # Add the statewide ECV to the district-level ECVs\n  mutate(total_ecv = district_total_ecv + ECV) |&gt;\n  filter(!is.na(total_ecv)) \n\necv_combined &lt;- ecv_combined |&gt; \n  group_by(year, candidate, party) |&gt; \n  summarise(total_ecv = sum(total_ecv), .groups = \"drop\") |&gt; # total ecv\n  arrange(year, total_ecv) |&gt; \n  group_by(year) |&gt; \n  mutate(winner = if_else(total_ecv == max(total_ecv), \"Yes\", \"No\")) |&gt;  # Mark winner\n  ungroup() \n\necv_combined |&gt; gt() |&gt;\n  tab_header(\n    title = \"District-Wide Winner-Take-All + State-Wide At Large Votes\"\n  ) |&gt;\n  cols_label( # display column names\n    year = \"Year\",\n    candidate = \"Candidate\",\n    party = \"Party\",\n    total_ecv = \"Electoral Votes\",\n    winner = \"Winning Candidate\"\n  )\n\n\n\n\n\n\n\n\nDistrict-Wide Winner-Take-All + State-Wide At Large Votes\n\n\nYear\nCandidate\nParty\nElectoral Votes\nWinning Candidate\n\n\n\n\n1976\nFORD, GERALD\nREPUBLICAN\n204\nNo\n\n\n1976\nCARTER, JIMMY\nDEMOCRAT\n362\nYes\n\n\n1980\nCARTER, JIMMY\nDEMOCRAT\n258\nNo\n\n\n1980\nREAGAN, RONALD\nREPUBLICAN\n287\nYes\n\n\n1984\nMONDALE, WALTER\nDEMOCRAT\n276\nNo\n\n\n1984\nREAGAN, RONALD\nREPUBLICAN\n283\nYes\n\n\n1988\nBUSH, GEORGE H.W.\nREPUBLICAN\n262\nNo\n\n\n1988\nDUKAKIS, MICHAEL\nDEMOCRAT\n292\nYes\n\n\n1992\nBUSH, GEORGE H.W.\nREPUBLICAN\n228\nNo\n\n\n1992\nCLINTON, BILL\nDEMOCRAT\n329\nYes\n\n\n1996\nCLINTON, BILL\nDEMOCRAT\n282\nNo\n\n\n1996\nDOLE, ROBERT\nREPUBLICAN\n283\nYes\n\n\n2000\nGORE, AL\nDEMOCRAT\n280\nNo\n\n\n2000\nBUSH, GEORGE W.\nREPUBLICAN\n290\nYes\n\n\n2004\nOTHER\nDEMOCRAT\n12\nNo\n\n\n2004\nKERRY, JOHN\nDEMOCRAT\n248\nNo\n\n\n2004\nBUSH, GEORGE W.\nREPUBLICAN\n299\nYes\n\n\n2008\nMCCAIN, JOHN\nREPUBLICAN\n224\nNo\n\n\n2008\nOBAMA, BARACK H.\nDEMOCRAT\n330\nYes\n\n\n2012\nOBAMA, BARACK H.\nDEMOCRAT\n275\nNo\n\n\n2012\nROMNEY, MITT\nREPUBLICAN\n286\nYes\n\n\n2016\nCLINTON, HILLARY\nDEMOCRAT\n291\nNo\n\n\n2016\nTRUMP, DONALD J.\nREPUBLICAN\n313\nYes\n\n\n2020\nTRUMP, DONALD J.\nREPUBLICAN\n263\nNo\n\n\n2020\nBIDEN, JOSEPH R. JR\nDEMOCRAT\n275\nYes\n\n\n\n\n\n\n\n\n\nCode\nggplot(ecv_combined, aes(x = factor(year), y = total_ecv, fill = party)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  #  keeps bars side-by-side\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\")) +\n  theme_minimal() +\n  labs(\n    title = \"Total ECV Votes for Each Candidate in U.S. Presidential Elections\",\n    x = \"Year\",\n    y = \"Total ECV\",\n    fill = \"Party\"\n  )"
  },
  {
    "objectID": "mp03.html#state-wide-proportional",
    "href": "mp03.html#state-wide-proportional",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "State-Wide Proportional",
    "text": "State-Wide Proportional\nUnder this system, electoral votes are distributed proportionally based on the percentage of votes each candidate receives in the state. If a candidate wins 60% of the vote in a state with 10 electoral votes, they get 60% of those electoral votes (6 ECVs). The approach here invovles calculating the total number of votes for each candidate in each state. Then, determine the proportion of the total vote that each candidate received in each state.\nNote: The rounding issue in proportional allocation methods does lead to the loss of some ECVs because, after rounding, the sum of the allocated votes may not match the total number of ECVs available for that state or for the entire country. Here, I allocate the remaining ECV to the candidate with the greatest proportion of votes.\n\n\nCode\n# Allocate ECVs based on that proportion with rounding \nstate_proportional_votes &lt;- PRESIDENT |&gt;\n  group_by(state, year) |&gt;\n  mutate(vote_share = candidatevotes / sum(candidatevotes)) |&gt; # Proportion of votes\n  ungroup() |&gt;\n  left_join(ECV, by = c(\"state\", \"year\")) |&gt;\n  mutate(proportional_ecv = round(vote_share * ecv))  # Round to allocate ECVs\n\n# Summarize the total ECVs for each candidate by state and year\nstate_proportional_summary &lt;- state_proportional_votes |&gt;\n  group_by(state, year, candidate, party_simplified) |&gt;\n  summarise(total_proportional_ecv = sum(proportional_ecv), .groups = \"drop\") |&gt;\n  arrange(state, year, total_proportional_ecv) |&gt;\n  group_by(state, year) |&gt;\n  # Mark the winner with the most ECVs in each state and year\n  mutate(winner = if_else(total_proportional_ecv == max(total_proportional_ecv), \"Yes\", \"No\")) |&gt; \n  ungroup() \n\n# When we use proportions and round, some ECV  go unallocated\n# Allocate ECVs proportionally and round down\nstate_wide_prop &lt;- PRESIDENT |&gt;\n  group_by(state, year) |&gt;\n  mutate(vote_share = candidatevotes / sum(candidatevotes)) |&gt; # Proportion of votes\n  ungroup() |&gt;\n  left_join(ECV, by = c(\"state\", \"year\")) |&gt;\n  mutate(prop_ecv = vote_share * ecv, round_prop_ecv = round(vote_share * ecv))  |&gt;  # Round ECVs\n  group_by(state, year) |&gt;\n  mutate(remaining_ecvs = ecv - sum(round_prop_ecv)) |&gt;  # Calculate how many ECVs are left to allocate\n  ungroup() |&gt;\n  \n  # assign remainder to the max unrounded proportion\n  group_by(state, year) |&gt;\n\n  mutate(final_ecv = ifelse(vote_share == max(vote_share), \n                            round_prop_ecv + remaining_ecvs, \n                            round_prop_ecv)) |&gt;  # Allocate remaining ECVs to the candidate with max vote share\n  ungroup() |&gt;\n  select(year, state, candidate, party_simplified, ecv, prop_ecv, round_prop_ecv, remaining_ecvs, final_ecv)\n\n# Summarize the total allocated ECVs for each candidate\nstate_wide_prop_summary &lt;- state_wide_prop |&gt;\n  group_by(state, year, candidate, party_simplified) |&gt;\n  summarise(total_prop_ecv = sum(final_ecv), .groups = \"drop\") |&gt;\n  group_by(year, state) |&gt;\n  mutate(winner = if_else(total_prop_ecv == max(total_prop_ecv), \"Yes\", \"No\")) |&gt; \n  ungroup() |&gt;\n  filter(total_prop_ecv &gt; 0) |&gt;\n  select(year, candidate, party_simplified, total_prop_ecv, winner)\n\n# across states for the year\nstate_wide_totals &lt;- state_wide_prop_summary |&gt;\n  group_by(year, candidate, party_simplified) |&gt;\n  summarise(total_ecv = sum(total_prop_ecv), .groups = \"drop\") |&gt;\n  group_by(year) |&gt;\n  mutate(winner = if_else(total_ecv == max(total_ecv), \"Yes\", \"No\")) |&gt; \n  ungroup() |&gt;\n  filter(total_ecv &gt; 0) |&gt;\n  select(year, candidate, party_simplified, total_ecv, winner) |&gt;\n  arrange(year, desc(total_ecv))\n\n\n\n\nCode\nggplot(state_wide_totals, aes(x = factor(year), y = total_ecv, fill = party_simplified)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  #  keeps bars side-by-side\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\", \"LIBERTARIAN\" = \"beige\", \"OTHER\" = \"gray\")) +\n  theme_minimal() +\n  labs(\n    title = \"Total ECV Votes for Each Candidate in U.S. Presidential Elections\",\n    x = \"Year\",\n    y = \"Total ECV\",\n    fill = \"Party\"\n  )\n\n\n\n\n\n\n\n\n\nCode\nstate_wide_totals |&gt; gt() |&gt;\n  tab_header(\n    title = \"State-Wide Proportional\"\n  ) |&gt;\n  cols_label( # display column names\n    year = \"Year\",\n    candidate = \"Candidate\",\n    party_simplified = \"Party\",\n    total_ecv = \"Electoral Votes\",\n    winner = \"Winning Candidate\"\n  )\n\n\n\n\n\n\n\n\nState-Wide Proportional\n\n\nYear\nCandidate\nParty\nElectoral Votes\nWinning Candidate\n\n\n\n\n1976\nCARTER, JIMMY\nDEMOCRAT\n270\nYes\n\n\n1976\nFORD, GERALD\nREPUBLICAN\n261\nNo\n\n\n1976\nFORD, GERALD\nOTHER\n2\nNo\n\n\n1976\nCARTER, JIMMY\nOTHER\n1\nNo\n\n\n1976\nOTHER\nOTHER\n1\nNo\n\n\n1980\nREAGAN, RONALD\nREPUBLICAN\n281\nYes\n\n\n1980\nCARTER, JIMMY\nDEMOCRAT\n220\nNo\n\n\n1980\nANDERSON, JOHN B.\nOTHER\n31\nNo\n\n\n1980\nREAGAN, RONALD\nOTHER\n2\nNo\n\n\n1980\nCLARK, EDWARD \"\"ED\"\"\nLIBERTARIAN\n1\nNo\n\n\n1984\nREAGAN, RONALD\nREPUBLICAN\n321\nYes\n\n\n1984\nMONDALE, WALTER\nDEMOCRAT\n211\nNo\n\n\n1984\nREAGAN, RONALD\nOTHER\n2\nNo\n\n\n1984\nMONDALE, WALTER\nOTHER\n1\nNo\n\n\n1988\nBUSH, GEORGE H.W.\nREPUBLICAN\n291\nYes\n\n\n1988\nDUKAKIS, MICHAEL\nDEMOCRAT\n242\nNo\n\n\n1988\nBUSH, GEORGE H.W.\nOTHER\n1\nNo\n\n\n1988\nDUKAKIS, MICHAEL\nOTHER\n1\nNo\n\n\n1992\nCLINTON, BILL\nDEMOCRAT\n226\nYes\n\n\n1992\nBUSH, GEORGE H.W.\nREPUBLICAN\n203\nNo\n\n\n1992\nPEROT, ROSS\nOTHER\n103\nNo\n\n\n1992\nBUSH, GEORGE H.W.\nOTHER\n2\nNo\n\n\n1992\nBLANK VOTE/SCATTERING\nOTHER\n1\nNo\n\n\n1996\nCLINTON, BILL\nDEMOCRAT\n262\nYes\n\n\n1996\nDOLE, ROBERT\nREPUBLICAN\n223\nNo\n\n\n1996\nPEROT, ROSS\nOTHER\n42\nNo\n\n\n1996\nNA\nOTHER\n4\nNo\n\n\n1996\nBLANK VOTE/SCATTERING\nOTHER\n1\nNo\n\n\n1996\nCLINTON, BILL\nOTHER\n1\nNo\n\n\n1996\nDOLE, ROBERT\nOTHER\n1\nNo\n\n\n1996\nNADER, RALPH\nOTHER\n1\nNo\n\n\n2000\nGORE, AL\nDEMOCRAT\n263\nYes\n\n\n2000\nBUSH, GEORGE W.\nREPUBLICAN\n262\nNo\n\n\n2000\nNADER, RALPH\nOTHER\n6\nNo\n\n\n2000\nBLANK VOTE/SCATTERING\nOTHER\n1\nNo\n\n\n2000\nBUSH, GEORGE W.\nOTHER\n1\nNo\n\n\n2000\nNOT DESIGNATED\nOTHER\n1\nNo\n\n\n2000\nNA\nOTHER\n1\nNo\n\n\n2004\nBUSH, GEORGE W.\nREPUBLICAN\n278\nYes\n\n\n2004\nKERRY, JOHN\nDEMOCRAT\n255\nNo\n\n\n2004\nBUSH, GEORGE W.\nOTHER\n1\nNo\n\n\n2004\nKERRY, JOHN\nOTHER\n1\nNo\n\n\n2008\nOBAMA, BARACK H.\nDEMOCRAT\n285\nYes\n\n\n2008\nMCCAIN, JOHN\nREPUBLICAN\n247\nNo\n\n\n2008\nMCCAIN, JOHN\nOTHER\n2\nNo\n\n\n2008\nOBAMA, BARACK H.\nOTHER\n1\nNo\n\n\n2012\nOBAMA, BARACK H.\nDEMOCRAT\n271\nYes\n\n\n2012\nROMNEY, MITT\nREPUBLICAN\n261\nNo\n\n\n2012\nJOHNSON, GARY\nLIBERTARIAN\n1\nNo\n\n\n2012\nOBAMA, BARACK H.\nOTHER\n1\nNo\n\n\n2012\nROMNEY, MITT\nOTHER\n1\nNo\n\n\n2016\nCLINTON, HILLARY\nDEMOCRAT\n265\nYes\n\n\n2016\nTRUMP, DONALD J.\nREPUBLICAN\n257\nNo\n\n\n2016\nJOHNSON, GARY\nLIBERTARIAN\n8\nNo\n\n\n2016\nCLINTON, HILLARY\nOTHER\n1\nNo\n\n\n2016\nMCMULLIN, EVAN\nOTHER\n1\nNo\n\n\n2016\nSTEIN, JILL\nOTHER\n1\nNo\n\n\n2016\nTRUMP, DONALD J.\nOTHER\n1\nNo\n\n\n2016\nNA\nOTHER\n1\nNo\n\n\n2020\nBIDEN, JOSEPH R. JR\nDEMOCRAT\n273\nYes\n\n\n2020\nTRUMP, DONALD J.\nREPUBLICAN\n264\nNo\n\n\n2020\nJORGENSEN, JO\nLIBERTARIAN\n1\nNo"
  },
  {
    "objectID": "mp03.html#national-proportional",
    "href": "mp03.html#national-proportional",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "National Proportional",
    "text": "National Proportional\nThis system allocates ECVs based on the national popular vote, not state-by-state. So, each state’s contribution to the national total is proportional to the number of votes received by each candidate in the national election. If Candidate A wins 60% of the total national popular vote and Candidate B wins 40%, Candidate A would receive 60% of the total ECVs, and Candidate B would get 40%, regardless of how they performed in any individual state. This system would reduce the importance of individual states and the swing state effect, and might make the election outcomes more directly tied to the national popular vote.\n\n\nCode\n# Find total ECV for each year \nelectoral_votes_available &lt;- ECV |&gt;\n  group_by(year) |&gt;\n  summarize(total_ecv = sum(ecv)) # sum ecv\n\nnation_wide_prop &lt;- PRESIDENT |&gt;\n  select(year, state, candidate, candidatevotes, party_simplified) |&gt;\n  group_by(year, candidate, party_simplified) |&gt;\n  summarize(candidate_total = sum(candidatevotes)) |&gt; # total votes nationwide per candidate per year\n  group_by(year) |&gt;\n  mutate(nation_total = sum(candidate_total)) |&gt;  # total votes nationwide per year\n  ungroup() |&gt;\n  mutate(prop_vote = (candidate_total / nation_total)) |&gt; # proportion of candidate votes to nationwide votes\n  select(-candidate_total, -nation_total) |&gt;\n  left_join(electoral_votes_available, join_by(year == year)) |&gt; # join with ECV\n  mutate(prop_ecv = round(prop_vote * total_ecv, digits = 0)) |&gt; # multiply proportion to total ecv that year\n  select(-prop_vote, -total_ecv) |&gt;\n  group_by(year)\n\n# Summarize the total allocated ECVs for each candidate\nnation_wide_summary &lt;- nation_wide_prop |&gt;\n  group_by(year) |&gt;\n  mutate(winner = if_else(prop_ecv == max(prop_ecv), \"Yes\", \"No\")) |&gt; \n  ungroup() |&gt;\n  filter(prop_ecv &gt; 0, !is.na(candidate)) |&gt;\n  select(year, candidate, prop_ecv, winner, party_simplified) |&gt;\n  arrange(year, desc(prop_ecv))\n\n\n\n\nCode\nggplot(nation_wide_summary, aes(x = factor(year), y = prop_ecv, fill = party_simplified)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +  #  keeps bars side-by-side\n  scale_fill_manual(values = c(\"DEMOCRAT\" = \"blue\", \"REPUBLICAN\" = \"red\", \"LIBERTARIAN\" = \"beige\", \"OTHER\" = \"gray\")) +\n  theme_minimal() +\n  labs(\n    title = \"Total ECV Votes for Each Candidate in U.S. Presidential Elections\",\n    x = \"Year\",\n    y = \"Total ECV\",\n    fill = \"Party\"\n  )\n\n\n\n\n\n\n\n\n\nCode\nnation_wide_summary |&gt; gt() |&gt;\n  tab_header(\n    title = \"Nation-Wide Proportional\"\n  ) |&gt;\n  cols_label( # display column names\n    year = \"Year\",\n    candidate = \"Candidate\",\n    party_simplified = \"Party\",\n    prop_ecv = \"Electoral Votes\",\n    winner = \"Winning Candidate\"\n  )\n\n\n\n\n\n\n\n\nNation-Wide Proportional\n\n\nYear\nCandidate\nElectoral Votes\nWinning Candidate\nParty\n\n\n\n\n1976\nCARTER, JIMMY\n267\nYes\nDEMOCRAT\n\n\n1976\nFORD, GERALD\n255\nNo\nREPUBLICAN\n\n\n1976\nMCCARTHY, EUGENE \"\"GENE\"\"\n4\nNo\nOTHER\n\n\n1976\nFORD, GERALD\n2\nNo\nOTHER\n\n\n1976\nANDERSON, THOMAS J.\n1\nNo\nOTHER\n\n\n1976\nCAMEJO, PETER\n1\nNo\nOTHER\n\n\n1976\nCARTER, JIMMY\n1\nNo\nOTHER\n\n\n1976\nMACBRIDE, ROGER\n1\nNo\nLIBERTARIAN\n\n\n1976\nMADDOX, LESTER\n1\nNo\nOTHER\n\n\n1976\nOTHER\n1\nNo\nOTHER\n\n\n1980\nREAGAN, RONALD\n270\nYes\nREPUBLICAN\n\n\n1980\nCARTER, JIMMY\n219\nNo\nDEMOCRAT\n\n\n1980\nANDERSON, JOHN B.\n35\nNo\nOTHER\n\n\n1980\nCLARK, EDWARD \"\"ED\"\"\n5\nNo\nLIBERTARIAN\n\n\n1980\nREAGAN, RONALD\n2\nNo\nOTHER\n\n\n1980\nCOMMONER, BARRY\n1\nNo\nOTHER\n\n\n1984\nREAGAN, RONALD\n313\nYes\nREPUBLICAN\n\n\n1984\nMONDALE, WALTER\n216\nNo\nDEMOCRAT\n\n\n1984\nREAGAN, RONALD\n2\nNo\nOTHER\n\n\n1984\nBERGLAND, DAVID\n1\nNo\nLIBERTARIAN\n\n\n1984\nMONDALE, WALTER\n1\nNo\nOTHER\n\n\n1988\nBUSH, GEORGE H.W.\n284\nYes\nREPUBLICAN\n\n\n1988\nDUKAKIS, MICHAEL\n244\nNo\nDEMOCRAT\n\n\n1988\nPAUL, RONALD \"\"RON\"\"\n2\nNo\nLIBERTARIAN\n\n\n1988\nBUSH, GEORGE H.W.\n1\nNo\nOTHER\n\n\n1988\nDUKAKIS, MICHAEL\n1\nNo\nOTHER\n\n\n1988\nFULANI, LENORA\n1\nNo\nOTHER\n\n\n1992\nCLINTON, BILL\n229\nYes\nDEMOCRAT\n\n\n1992\nBUSH, GEORGE H.W.\n198\nNo\nREPUBLICAN\n\n\n1992\nPEROT, ROSS\n101\nNo\nOTHER\n\n\n1992\nBUSH, GEORGE H.W.\n2\nNo\nOTHER\n\n\n1992\nBLANK VOTE/SCATTERING\n1\nNo\nOTHER\n\n\n1992\nMARROU, ANDRE\n1\nNo\nLIBERTARIAN\n\n\n1996\nCLINTON, BILL\n263\nYes\nDEMOCRAT\n\n\n1996\nDOLE, ROBERT\n216\nNo\nREPUBLICAN\n\n\n1996\nPEROT, ROSS\n42\nNo\nOTHER\n\n\n1996\nBROWNE, HARRY\n3\nNo\nLIBERTARIAN\n\n\n1996\nNADER, RALPH\n3\nNo\nOTHER\n\n\n1996\nBLANK VOTE/SCATTERING\n1\nNo\nOTHER\n\n\n1996\nCLINTON, BILL\n1\nNo\nOTHER\n\n\n1996\nDOLE, ROBERT\n1\nNo\nOTHER\n\n\n1996\nHAGELIN, JOHN\n1\nNo\nOTHER\n\n\n1996\nPHILLIPS, HOWARD\n1\nNo\nOTHER\n\n\n2000\nGORE, AL\n258\nYes\nDEMOCRAT\n\n\n2000\nBUSH, GEORGE W.\n255\nNo\nREPUBLICAN\n\n\n2000\nNADER, RALPH\n13\nNo\nOTHER\n\n\n2000\nBROWNE, HARRY\n2\nNo\nLIBERTARIAN\n\n\n2000\nBUCHANAN, PATRICK \"\"PAT\"\"\n2\nNo\nOTHER\n\n\n2000\nBLANK VOTE/SCATTERING\n1\nNo\nOTHER\n\n\n2000\nBUSH, GEORGE W.\n1\nNo\nOTHER\n\n\n2000\nGORE, AL\n1\nNo\nOTHER\n\n\n2000\nNOT DESIGNATED\n1\nNo\nOTHER\n\n\n2004\nBUSH, GEORGE W.\n271\nYes\nREPUBLICAN\n\n\n2004\nKERRY, JOHN\n258\nNo\nDEMOCRAT\n\n\n2004\nBADNARIK, MICHAEL\n2\nNo\nLIBERTARIAN\n\n\n2004\nNADER, RALPH\n2\nNo\nOTHER\n\n\n2004\nBUSH, GEORGE W.\n1\nNo\nOTHER\n\n\n2004\nCOBB, DAVID\n1\nNo\nOTHER\n\n\n2004\nKERRY, JOHN\n1\nNo\nOTHER\n\n\n2004\nOTHER\n1\nNo\nOTHER\n\n\n2004\nPEROUTKA, MICHAEL\n1\nNo\nOTHER\n\n\n2008\nOBAMA, BARACK H.\n282\nYes\nDEMOCRAT\n\n\n2008\nMCCAIN, JOHN\n243\nNo\nREPUBLICAN\n\n\n2008\nNADER, RALPH\n3\nNo\nOTHER\n\n\n2008\nBARR, BOB\n2\nNo\nLIBERTARIAN\n\n\n2008\nBALDWIN, CHARLES \"\"CHUCK\"\"\n1\nNo\nOTHER\n\n\n2008\nMCCAIN, JOHN\n1\nNo\nOTHER\n\n\n2008\nMCKINNEY, CYNTHIA\n1\nNo\nOTHER\n\n\n2008\nOBAMA, BARACK H.\n1\nNo\nOTHER\n\n\n2012\nOBAMA, BARACK H.\n272\nYes\nDEMOCRAT\n\n\n2012\nROMNEY, MITT\n251\nNo\nREPUBLICAN\n\n\n2012\nJOHNSON, GARY\n5\nNo\nLIBERTARIAN\n\n\n2012\nSTEIN, JILL\n2\nNo\nOTHER\n\n\n2012\nOBAMA, BARACK H.\n1\nNo\nOTHER\n\n\n2012\nROMNEY, MITT\n1\nNo\nOTHER\n\n\n2016\nCLINTON, HILLARY\n257\nYes\nDEMOCRAT\n\n\n2016\nTRUMP, DONALD J.\n245\nNo\nREPUBLICAN\n\n\n2016\nJOHNSON, GARY\n16\nNo\nLIBERTARIAN\n\n\n2016\nSTEIN, JILL\n5\nNo\nOTHER\n\n\n2016\nMCMULLIN, EVAN\n2\nNo\nOTHER\n\n\n2016\nBLANK VOTE\n1\nNo\nOTHER\n\n\n2016\nCASTLE, DARRELL L.\n1\nNo\nOTHER\n\n\n2016\nCLINTON, HILLARY\n1\nNo\nOTHER\n\n\n2016\nOTHER\n1\nNo\nOTHER\n\n\n2016\nSCATTERING\n1\nNo\nOTHER\n\n\n2016\nTRUMP, DONALD J.\n1\nNo\nOTHER\n\n\n2020\nBIDEN, JOSEPH R. JR\n276\nYes\nDEMOCRAT\n\n\n2020\nTRUMP, DONALD J.\n252\nNo\nREPUBLICAN\n\n\n2020\nJORGENSEN, JO\n6\nNo\nLIBERTARIAN\n\n\n2020\nHAWKINS, HOWIE\n1\nNo\nOTHER"
  },
  {
    "objectID": "mp03.html#what-does-fairness-mean",
    "href": "mp03.html#what-does-fairness-mean",
    "title": "Do Proportional Electoral College Allocations Yield a More Representative Presidency?",
    "section": "What Does “Fairness” Mean?",
    "text": "What Does “Fairness” Mean?\nWhen I think about fairness in the context of ECV allocation, it generally relates to how well the system: 1. Represents the popular vote: Does the distribution of ECVs accurately reflect the number of votes cast for each candidate? A system that over-represents or under-represents certain groups could be considered unfair. 2. Accounts for each state: In systems like the current winner-take-all method, small states with fewer voters might have a disproportionately large influence in electing a president compared to larger states. In contrast, a proportional system might mitigate this imbalance. 3. Minimizes “winner-take-all” advantages: A system where a candidate wins by just a small margin but takes all of a state’s ECVs could be seen as unfair because the losing candidate might have had broad support across the state, but doesn’t get any representation.\n\nTruthfulness Score\nClaim: claim under evaluation is: “The Electoral College system is biased and over-represents smaller states, giving them an unfair advantage in electing the president.” The scale I’ll use is a 5-point scale, ranging from 1 to 5, where: 1. False – The claim is completely inaccurate, with no evidence to support it. 2. Mostly False – The claim contains significant inaccuracies or overgeneralizations, with some misleading aspects. 3. Half-True – The claim is partially accurate but misses key details or context that would provide a more complete picture. 4. Mostly True – The claim is largely accurate, with very minor misstatements or nuances that don’t change the overall truth. 5. True – The claim is completely accurate, with no significant errors or misleading information.\nScore: 4 Under the State-Wide Winner-Take-All system, smaller states do indeed have a disproportionately large impact because of the fixed 2 Senate seats each state gets, regardless of population. This benefits candidates who win a disproportionate share of votes in less populous states.\nPew Research Center In September of 2024, the Pew published that the article: Majority of Americans Continue to Favor Moving Away from Electoral College. Following the 2000 and 2016 elections, where the winners of the popular vote received fewer Electoral College votes than their opponents, the Pew surveyed we surveyed 9,720 U.S. adults."
  },
  {
    "objectID": "mp01.html",
    "href": "mp01.html",
    "title": "US Public Transit System Data Analysis",
    "section": "",
    "text": "When I was in Japan, I got to ride some of the most efficient transit systems in the world, characterized by its punctuality, its service, and the large numbers of passengers. Here in the United States, public transit is a whole different story. At the end of this analysis, I want to figure out what the most efficient transit system in the country is. How do I define efficiency? To me, efficiency can be broken down into ridership (trips, miles, the functionality) and financial efficiency (revenue, expenses). In this project, I will be investigating the usage and financial statistics of the US transit systems."
  },
  {
    "objectID": "mp01.html#introduction",
    "href": "mp01.html#introduction",
    "title": "US Public Transit System Data Analysis",
    "section": "",
    "text": "When I was in Japan, I got to ride some of the most efficient transit systems in the world, characterized by its punctuality, its service, and the large numbers of passengers. Here in the United States, public transit is a whole different story. At the end of this analysis, I want to figure out what the most efficient transit system in the country is. How do I define efficiency? To me, efficiency can be broken down into ridership (trips, miles, the functionality) and financial efficiency (revenue, expenses). In this project, I will be investigating the usage and financial statistics of the US transit systems."
  },
  {
    "objectID": "mp01.html#data-sets",
    "href": "mp01.html#data-sets",
    "title": "US Public Transit System Data Analysis",
    "section": "Data Sets",
    "text": "Data Sets\nThe National Transit Database (NTD) records the financial and operations of transit systems to keep track of the industry and provide public information and statistics. The data is collected by transit agencies and submitted to the Federal Administration (FTA) annually and reviewed by the FTA. The most recent and complete information available at the moment is for 2022. Let’s dive into it by exploring the following data sets from the FTA:\n\n2022 Fare Revenue\n2022 Expenses\nRidership\n\nI will be extracting data on fares, expenses,\n\nFare Revenue Data\n\n\n\n\n\n\n\n\nExpenses Data\n\n\n\n\n\n\n\n\nFinancials Data\nWe can inner join the Revenue and Expenses data into a more comprehensiive financials data set that we can do our analysis with.\nHere’s a sample of the Financials Data.\n\n\n\n\n\n\n\n\nTrips Data\nFrom the ridership data, I will be extracting information on public transportation trips taken by unlinked passengers.\n\n\n\n\n\n\n\n\nMiles Data\nAlso from the ridership data, I will be extracting information on the vehicle revenue miles.\n\n\n\n\n\n\n\n\nUsage Data\nWe can inner join the Trips and Miles data together using NTD ID into a data set on the usage.\nAttributes\nSome of the attribute namings are unclear so let’s use the FTA Glossary to interpret the data.\nRenaming\n\nrenaming UZA Name to metro_area\nreplacing the modes with their respective full names\nrenaming UPT to unlinked_passenger_trips\nrenaming VRM to vehicle_revenue_miles\n\nVRM (vehicle revenue miles): The miles that vehicles travel while in revenue service.\nUPT (unlinked passenger trips): The number of passengers who board public transportation vehicles. Passengers are counted each time they board vehicles no matter how many vehicles they use to travel from their origin to their destination.\nNow,, here’s a sample of the processed Usage Data.\n\n\n\n\n\n\n\n\nJoin Usage and Financial Data\nNext, we can join the Usage and Financial Data sets.\nIn order to do so, we need to get the Usage for 2022 in order to match the 2022 Financial data.\nSince we are joining on Mode, we need to convert the modes of the Financials data as well.\nAfter that, we can LEFT JOIN the two data sets.\nLet’s take a look at the Usage and Financials data."
  },
  {
    "objectID": "mp01.html#project-outcomes",
    "href": "mp01.html#project-outcomes",
    "title": "US Public Transit System Data Analysis",
    "section": "Project Outcomes",
    "text": "Project Outcomes\nI used summary statistics to explore the data sets processed above to extract insights that can shed light on efficiency of the US Public Transit Systems.\nLibraries: tidyverse, dplyr\nLet’s see what the data can tell us about public transit in the US looking at transit Usage and Financial data.\n\nVehicle Revenue Miles\nWhat transit agency had the most total VRM in this sample?\nMTA New York City Transit with 10832855350 total miles\n\nlibrary(dplyr)\nUSAGE |&gt; \n  group_by(Agency) |&gt;\n  summarise(total_VRM = sum(vehicle_revenue_miles)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1)\n\n# A tibble: 1 × 2\n  Agency                      total_VRM\n  &lt;chr&gt;                           &lt;dbl&gt;\n1 MTA New York City Transit 10832855350\n\n\nWhat transit mode had the most total VRM in this sample?\nThe Bus at 49444494088 total miles\n\nUSAGE |&gt;\n  group_by(Mode) |&gt;\n  summarise(total_VRM = sum(vehicle_revenue_miles)) |&gt;\n  arrange(desc(total_VRM)) |&gt;\n  slice(1)\n\n# A tibble: 1 × 2\n  Mode    total_VRM\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Bus   49444494088\n\n\nWhat mode of transport had the longest average trip in May 2024?\nThe Heavy Rail did with 2654864 average miles\n\nUSAGE |&gt; \n  filter(month == \"2024-05-01\") |&gt; \n  group_by(Mode) |&gt; \n  summarise(average_VRM = mean(vehicle_revenue_miles)) |&gt; \n  arrange(desc(average_VRM)) |&gt;\n  slice(1)\n\n# A tibble: 1 × 2\n  Mode       average_VRM\n  &lt;chr&gt;            &lt;dbl&gt;\n1 Heavy Rail    2654864.\n\n\n\n\nUnlinked Passenger Trips\nHow many trips were taken on the NYC Subway (Heavy Rail) in May 2024?\nA total of 237383777 trips were taken.\n\nTRIPS |&gt; \n  filter(Mode == \"HR\", month == \"2024-05-01\") |&gt; \n  summarise(total_trips = sum(UPT))\n\n# A tibble: 1 × 1\n  total_trips\n        &lt;dbl&gt;\n1   237383777\n\n\nHow much did NYC subway ridership fall between April 2019 and April 2020?\nRidership fell by 296864650 between April 2018 and April 2020.\n\napril_2020 &lt;- USAGE |&gt; \n  filter(Mode == \"Heavy Rail\") |&gt; \n  filter(month == \"2020-04-01\") |&gt; \n  summarise(total_riders = sum(unlinked_passenger_trips))\n\napril_2019 &lt;- USAGE |&gt; \n  filter(Mode == \"Heavy Rail\") |&gt; \n  filter(month == \"2019-04-01\") |&gt; \n  summarise(total_riders = sum(unlinked_passenger_trips))\n\ndifference = abs(april_2020 - april_2019)\nprint(difference)\n\n  total_riders\n1    296864650\n\n\nWhich transit system (agency and mode) had the most UPT in 2022?\nThe MTA New York City Transit Heavy Rail had the most UPT in 2022 at 1793073801.\n\nUSAGE_AND_FINANCIALS |&gt; select(Agency, Mode, UPT) |&gt; \n  arrange(desc(UPT))|&gt;\n  slice(1)\n\n# A tibble: 1 × 3\n  Agency                    Mode              UPT\n  &lt;chr&gt;                     &lt;chr&gt;           &lt;dbl&gt;\n1 MTA New York City Transit Heavy Rail 1793073801\n\n\n\n\nThree more interesting transit facts\nWhich month had the highest number of average trips between 2002 and 2024?\nOctober with an average of 768205 trips.\n\nUSAGE &lt;- USAGE |&gt; mutate(month_number = month(month))\nUSAGE |&gt; group_by(month_number) |&gt; summarise(avg_UPT = mean(unlinked_passenger_trips)) |&gt; arrange(desc(avg_UPT)) |&gt;\n  slice(1)\n\n# A tibble: 1 × 2\n  month_number avg_UPT\n         &lt;dbl&gt;   &lt;dbl&gt;\n1           10 768206.\n\nUSAGE &lt;- USAGE |&gt; select(-month_number)\n\nWhich metro area had the most unlinked passenger trips?\nThe New York, Jersey City, and Newark area has the greatest total UPT.\n\nUSAGE |&gt; group_by(metro_area) |&gt; \n  summarise(total_UPT = sum(unlinked_passenger_trips)) |&gt; \n  arrange(desc(total_UPT)) |&gt; \n  slice(1)\n\n# A tibble: 1 × 2\n  metro_area                              total_UPT\n  &lt;chr&gt;                                       &lt;dbl&gt;\n1 New York--Jersey City--Newark, NY--NJ 84020935224\n\n\nWhich metro area offers the most modes of transit?\nSan Francisco–Oakland, CA with 13 Modes\n\nUSAGE |&gt; group_by(metro_area) |&gt; \n  summarise(mode_count = n_distinct(Mode)) |&gt; \n  arrange(desc(mode_count)) |&gt; \n  slice(1)\n\n# A tibble: 1 × 2\n  metro_area                 mode_count\n  &lt;chr&gt;                           &lt;int&gt;\n1 San Francisco--Oakland, CA         13\n\n\n\ndistinct(USAGE |&gt; select(Mode, metro_area) |&gt; filter(metro_area == \"San Francisco--Oakland, CA\"))\n\n# A tibble: 13 × 2\n   Mode              metro_area                \n   &lt;chr&gt;             &lt;chr&gt;                     \n 1 Heavy Rail        San Francisco--Oakland, CA\n 2 Monorail          San Francisco--Oakland, CA\n 3 Demand Response   San Francisco--Oakland, CA\n 4 Bus               San Francisco--Oakland, CA\n 5 Commuter Bus      San Francisco--Oakland, CA\n 6 Bus Rapid Transit San Francisco--Oakland, CA\n 7 Cable Car         San Francisco--Oakland, CA\n 8 Light Rail        San Francisco--Oakland, CA\n 9 Streetcar         San Francisco--Oakland, CA\n10 Trolleybus        San Francisco--Oakland, CA\n11 Ferryboat         San Francisco--Oakland, CA\n12 Vanpool           San Francisco--Oakland, CA\n13 Commuter Rail     San Francisco--Oakland, CA"
  },
  {
    "objectID": "mp01.html#financial-efficiency",
    "href": "mp01.html#financial-efficiency",
    "title": "US Public Transit System Data Analysis",
    "section": "Financial Efficiency",
    "text": "Financial Efficiency\n\nFarebox Recovery Among Major Systems\nFarebox recovery is defined as the highest ratio of Total Fares to Expenses and can be used to measure efficiency.\nWhich transit system (agency and mode) had the highest farebox recovery?\nTransit Authority of Central Kentucky Vanpool has the highest farebox recovery at 2.38.\n\nUSAGE_AND_FINANCIALS |&gt; select(Agency, Mode, `Total Fares`, Expenses) |&gt; \n  mutate(farebox_recovery = `Total Fares`/Expenses) |&gt; \n  arrange(desc(farebox_recovery))|&gt;\n  slice(1)\n\n# A tibble: 1 × 5\n  Agency                           Mode  `Total Fares` Expenses farebox_recovery\n  &lt;chr&gt;                            &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;\n1 Transit Authority of Central Ke… Vanp…         97300    40801             2.38\n\n\nWhich transit system (agency and mode) has the lowest expenses per UPT?\nSan Francisco Bay Area Rapid Transit District Heavy Rail has the lowest expenses per UPT at 0.396.\n\nUSAGE_AND_FINANCIALS |&gt; select(Agency, Mode, UPT, Expenses) |&gt; \n  mutate(Expenses_per_UPT = Expenses/UPT) |&gt; \n  arrange(Expenses_per_UPT)|&gt;\n  slice(1)\n\n# A tibble: 1 × 5\n  Agency                                  Mode     UPT Expenses Expenses_per_UPT\n  &lt;chr&gt;                                   &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt;            &lt;dbl&gt;\n1 San Francisco Bay Area Rapid Transit D… Heav… 4.53e7 17965407            0.396\n\n\nWhich transit system (agency and mode) has the highest total fares per UPT?\nThe highest total fares per UPT belongs to Altoona Metro Transit’s Demand Response at 656 per UPT.\n\nUSAGE_AND_FINANCIALS |&gt; select(Agency, Mode, `Total Fares`, UPT) |&gt; \n  mutate(Total_Fares_per_UPT = `Total Fares`/UPT) |&gt; \n  arrange(desc(Total_Fares_per_UPT))|&gt;\n  slice(1)\n\n# A tibble: 1 × 5\n  Agency                Mode            `Total Fares`   UPT Total_Fares_per_UPT\n  &lt;chr&gt;                 &lt;chr&gt;                   &lt;dbl&gt; &lt;dbl&gt;               &lt;dbl&gt;\n1 Altoona Metro Transit Demand Response         17058    26                656.\n\n\nWhich transit system (agency and mode) has the lowest expenses per VRM?\nSan Francisco Bay Area Rapid Transit District’s Heavy Rail at 0.217 per VRM.\n\nUSAGE_AND_FINANCIALS |&gt; select(Agency, Mode, Expenses, VRM) |&gt; \n  mutate(Expense_VRM = Expenses/VRM) |&gt; \n  arrange(Expense_VRM)|&gt;\n  slice(1)\n\n# A tibble: 1 × 5\n  Agency                                       Mode  Expenses    VRM Expense_VRM\n  &lt;chr&gt;                                        &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n1 San Francisco Bay Area Rapid Transit Distri… Heav… 17965407 8.27e7       0.217\n\n\nWhich transit system (agency and mode) has the highest total fares per VRM?\nChicago Water Taxi (Wendella)’s Ferryboat at 237 total fares per VRM\n\nUSAGE_AND_FINANCIALS |&gt; select(Agency, Mode, `Total Fares`, VRM) |&gt; \n  mutate(Fares_VRM = `Total Fares`/VRM) |&gt;\n  arrange(desc(Fares_VRM)) |&gt;\n  slice(1)\n\n# A tibble: 1 × 5\n  Agency                        Mode      `Total Fares`   VRM Fares_VRM\n  &lt;chr&gt;                         &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 Chicago Water Taxi (Wendella) Ferryboat        142473   600      237."
  },
  {
    "objectID": "mp01.html#conclusion",
    "href": "mp01.html#conclusion",
    "title": "US Public Transit System Data Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nIn terms of ridership, the MTA New York City Transit takes the win in with the most Vehicle Revenue Miles and the most Unlinked Passenger Trips in 2022. Ridership in the NYC, NJ, Newark area overall is the highest and the transit systems in the area are some of the most utilized public transit systems in the US. Financially, San Francisco’s BART Heavy Rail/Subway comes out on top with both the lowest expense per VRM and lowest expense per UPT. Additionally, San Francisco/Oakland, CA also offers the most modes of transportation. When it comes to usage, the MTA is the transit system that shines, covering the most revenue miles with its vehicles and servicing the most passenger trips. When finances are added to the picture, the BART seems to be the most cost effective transit system."
  }
]